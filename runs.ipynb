{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Setup\n",
    "\n",
    "Run the following models:\n",
    "   * DetectorRS (Two Stage Detector) - Based on Faster RCNN, 2020\n",
    "       * https://arxiv.org/pdf/2006.02334 \n",
    "       * https://medium.com/visionwizard/detectors-state-of-the-art-object-detector-from-google-research-e0b89abdd1fc\n",
    "   * DINO (Transformer Detector) - Based on DETR, 2022\n",
    "       * https://arxiv.org/pdf/2104.14294\n",
    "       * https://sh-tsang.medium.com/review-dino-emerging-properties-in-self-supervised-vision-transformers-cfddbb4d3549\n",
    "   * YOLOX (One Stage Detector) - Based on YOLO, 2021\n",
    "       * https://arxiv.org/pdf/2107.08430 \n",
    "       * https://gmongaras.medium.com/yolox-explanation-what-is-yolox-and-what-makes-it-special-c01f6a8a0830\n",
    "    \n",
    "Use the following dataset:\n",
    "   * MS COCO Dataset Val2017 (https://cocodataset.org/#download)\n",
    "\n",
    "Tools:\n",
    "   * Python 3.11\n",
    "   * Pytorch 2.1.0\n",
    "   * MMDetection Library 3.3.0\n",
    "\n",
    "Hardware:\n",
    "   * Nvidia RTX 3070 8GB VRAM\n",
    "   * Ryzen 3900X\n",
    "   * 32 GB RAM\n",
    "\n",
    "Compare on the following metrics:\n",
    "   * mAP @ IoU=0.50:0.95 | area = all\n",
    "   * mAP @ IoU=0.50:0.95 | area = small\n",
    "   * Runtime"
   ],
   "id": "d3f59b90f86134ce"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Results\n",
    "\n",
    "| Model     | mAP@0.5:0.95 all | mAP@0.5:0.95 small | Runtime    |\n",
    "|-----------|------------------|--------------------|------------|\n",
    "| DetectoRS | 0.438            | 0.224              | 26 min 9s  |\n",
    "| DINO      | 0.583            | 0.415              | 36 min 46s |\n",
    "| YOLOX     | 0.506            | 0.320              | 2 min 36s  |\n",
    "\n"
   ],
   "id": "b93aaec5f6cd46ab"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# DetectoRS",
   "id": "ad774717e1296bae"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T23:24:42.550516Z",
     "start_time": "2024-05-10T22:56:56.638637Z"
    }
   },
   "cell_type": "code",
   "source": "!python tools/test.py configs/detectors/detectors_htc-r101_20e_coco.py checkpoints/detectors_htc_r101_20e_coco_20210419_203638-348d533b.pth",
   "id": "3a612da1779dec85",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/11 00:56:59 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - \r\n",
      "------------------------------------------------------------\r\n",
      "System environment:\r\n",
      "    sys.platform: linux\r\n",
      "    Python: 3.11.9 (main, Apr 17 2024, 00:00:00) [GCC 13.2.1 20240316 (Red Hat 13.2.1-7)]\r\n",
      "    CUDA available: True\r\n",
      "    MUSA available: False\r\n",
      "    numpy_random_seed: 622920327\r\n",
      "    GPU 0: NVIDIA GeForce RTX 3070\r\n",
      "    CUDA_HOME: /usr/local/cuda\r\n",
      "    NVCC: Cuda compilation tools, release 12.4, V12.4.131\r\n",
      "    GCC: gcc (GCC) 13.2.1 20240316 (Red Hat 13.2.1-7)\r\n",
      "    PyTorch: 2.1.0+cu121\r\n",
      "    PyTorch compiling details: PyTorch built with:\r\n",
      "  - GCC 9.3\r\n",
      "  - C++ Version: 201703\r\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\r\n",
      "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\r\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\r\n",
      "  - LAPACK is enabled (usually provided by MKL)\r\n",
      "  - NNPACK is enabled\r\n",
      "  - CPU capability usage: AVX2\r\n",
      "  - CUDA Runtime 12.1\r\n",
      "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\r\n",
      "  - CuDNN 8.9.2\r\n",
      "  - Magma 2.6.1\r\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \r\n",
      "\r\n",
      "    TorchVision: 0.16.0+cu121\r\n",
      "    OpenCV: 4.9.0\r\n",
      "    MMEngine: 0.10.4\r\n",
      "\r\n",
      "Runtime environment:\r\n",
      "    cudnn_benchmark: False\r\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\r\n",
      "    dist_cfg: {'backend': 'nccl'}\r\n",
      "    seed: 622920327\r\n",
      "    Distributed launcher: none\r\n",
      "    Distributed training: False\r\n",
      "    GPU number: 1\r\n",
      "------------------------------------------------------------\r\n",
      "\r\n",
      "05/11 00:56:59 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Config:\r\n",
      "auto_scale_lr = dict(base_batch_size=16, enable=False)\r\n",
      "backend_args = None\r\n",
      "data_root = 'data/coco/'\r\n",
      "dataset_type = 'CocoDataset'\r\n",
      "default_hooks = dict(\r\n",
      "    checkpoint=dict(interval=1, type='CheckpointHook'),\r\n",
      "    logger=dict(interval=50, type='LoggerHook'),\r\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\r\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\r\n",
      "    timer=dict(type='IterTimerHook'),\r\n",
      "    visualization=dict(type='DetVisualizationHook'))\r\n",
      "default_scope = 'mmdet'\r\n",
      "env_cfg = dict(\r\n",
      "    cudnn_benchmark=False,\r\n",
      "    dist_cfg=dict(backend='nccl'),\r\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\r\n",
      "launcher = 'none'\r\n",
      "load_from = 'checkpoints/detectors_htc_r101_20e_coco_20210419_203638-348d533b.pth'\r\n",
      "log_level = 'INFO'\r\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\r\n",
      "max_epochs = 20\r\n",
      "model = dict(\r\n",
      "    backbone=dict(\r\n",
      "        conv_cfg=dict(type='ConvAWS'),\r\n",
      "        depth=101,\r\n",
      "        frozen_stages=1,\r\n",
      "        init_cfg=dict(checkpoint='torchvision://resnet101', type='Pretrained'),\r\n",
      "        norm_cfg=dict(requires_grad=True, type='BN'),\r\n",
      "        norm_eval=True,\r\n",
      "        num_stages=4,\r\n",
      "        out_indices=(\r\n",
      "            0,\r\n",
      "            1,\r\n",
      "            2,\r\n",
      "            3,\r\n",
      "        ),\r\n",
      "        output_img=True,\r\n",
      "        sac=dict(type='SAC', use_deform=True),\r\n",
      "        stage_with_sac=(\r\n",
      "            False,\r\n",
      "            True,\r\n",
      "            True,\r\n",
      "            True,\r\n",
      "        ),\r\n",
      "        style='pytorch',\r\n",
      "        type='DetectoRS_ResNet'),\r\n",
      "    data_preprocessor=dict(\r\n",
      "        bgr_to_rgb=True,\r\n",
      "        mean=[\r\n",
      "            123.675,\r\n",
      "            116.28,\r\n",
      "            103.53,\r\n",
      "        ],\r\n",
      "        pad_seg=True,\r\n",
      "        pad_size_divisor=32,\r\n",
      "        std=[\r\n",
      "            58.395,\r\n",
      "            57.12,\r\n",
      "            57.375,\r\n",
      "        ],\r\n",
      "        type='DetDataPreprocessor'),\r\n",
      "    neck=dict(\r\n",
      "        aspp_dilations=(\r\n",
      "            1,\r\n",
      "            3,\r\n",
      "            6,\r\n",
      "            1,\r\n",
      "        ),\r\n",
      "        aspp_out_channels=64,\r\n",
      "        in_channels=[\r\n",
      "            256,\r\n",
      "            512,\r\n",
      "            1024,\r\n",
      "            2048,\r\n",
      "        ],\r\n",
      "        num_outs=5,\r\n",
      "        out_channels=256,\r\n",
      "        rfp_backbone=dict(\r\n",
      "            conv_cfg=dict(type='ConvAWS'),\r\n",
      "            depth=101,\r\n",
      "            frozen_stages=1,\r\n",
      "            norm_cfg=dict(requires_grad=True, type='BN'),\r\n",
      "            norm_eval=True,\r\n",
      "            num_stages=4,\r\n",
      "            out_indices=(\r\n",
      "                0,\r\n",
      "                1,\r\n",
      "                2,\r\n",
      "                3,\r\n",
      "            ),\r\n",
      "            pretrained='torchvision://resnet101',\r\n",
      "            rfp_inplanes=256,\r\n",
      "            sac=dict(type='SAC', use_deform=True),\r\n",
      "            stage_with_sac=(\r\n",
      "                False,\r\n",
      "                True,\r\n",
      "                True,\r\n",
      "                True,\r\n",
      "            ),\r\n",
      "            style='pytorch',\r\n",
      "            type='DetectoRS_ResNet'),\r\n",
      "        rfp_steps=2,\r\n",
      "        type='RFP'),\r\n",
      "    roi_head=dict(\r\n",
      "        bbox_head=[\r\n",
      "            dict(\r\n",
      "                bbox_coder=dict(\r\n",
      "                    target_means=[\r\n",
      "                        0.0,\r\n",
      "                        0.0,\r\n",
      "                        0.0,\r\n",
      "                        0.0,\r\n",
      "                    ],\r\n",
      "                    target_stds=[\r\n",
      "                        0.1,\r\n",
      "                        0.1,\r\n",
      "                        0.2,\r\n",
      "                        0.2,\r\n",
      "                    ],\r\n",
      "                    type='DeltaXYWHBBoxCoder'),\r\n",
      "                fc_out_channels=1024,\r\n",
      "                in_channels=256,\r\n",
      "                loss_bbox=dict(beta=1.0, loss_weight=1.0, type='SmoothL1Loss'),\r\n",
      "                loss_cls=dict(\r\n",
      "                    loss_weight=1.0,\r\n",
      "                    type='CrossEntropyLoss',\r\n",
      "                    use_sigmoid=False),\r\n",
      "                num_classes=80,\r\n",
      "                reg_class_agnostic=True,\r\n",
      "                roi_feat_size=7,\r\n",
      "                type='Shared2FCBBoxHead'),\r\n",
      "            dict(\r\n",
      "                bbox_coder=dict(\r\n",
      "                    target_means=[\r\n",
      "                        0.0,\r\n",
      "                        0.0,\r\n",
      "                        0.0,\r\n",
      "                        0.0,\r\n",
      "                    ],\r\n",
      "                    target_stds=[\r\n",
      "                        0.05,\r\n",
      "                        0.05,\r\n",
      "                        0.1,\r\n",
      "                        0.1,\r\n",
      "                    ],\r\n",
      "                    type='DeltaXYWHBBoxCoder'),\r\n",
      "                fc_out_channels=1024,\r\n",
      "                in_channels=256,\r\n",
      "                loss_bbox=dict(beta=1.0, loss_weight=1.0, type='SmoothL1Loss'),\r\n",
      "                loss_cls=dict(\r\n",
      "                    loss_weight=1.0,\r\n",
      "                    type='CrossEntropyLoss',\r\n",
      "                    use_sigmoid=False),\r\n",
      "                num_classes=80,\r\n",
      "                reg_class_agnostic=True,\r\n",
      "                roi_feat_size=7,\r\n",
      "                type='Shared2FCBBoxHead'),\r\n",
      "            dict(\r\n",
      "                bbox_coder=dict(\r\n",
      "                    target_means=[\r\n",
      "                        0.0,\r\n",
      "                        0.0,\r\n",
      "                        0.0,\r\n",
      "                        0.0,\r\n",
      "                    ],\r\n",
      "                    target_stds=[\r\n",
      "                        0.033,\r\n",
      "                        0.033,\r\n",
      "                        0.067,\r\n",
      "                        0.067,\r\n",
      "                    ],\r\n",
      "                    type='DeltaXYWHBBoxCoder'),\r\n",
      "                fc_out_channels=1024,\r\n",
      "                in_channels=256,\r\n",
      "                loss_bbox=dict(beta=1.0, loss_weight=1.0, type='SmoothL1Loss'),\r\n",
      "                loss_cls=dict(\r\n",
      "                    loss_weight=1.0,\r\n",
      "                    type='CrossEntropyLoss',\r\n",
      "                    use_sigmoid=False),\r\n",
      "                num_classes=80,\r\n",
      "                reg_class_agnostic=True,\r\n",
      "                roi_feat_size=7,\r\n",
      "                type='Shared2FCBBoxHead'),\r\n",
      "        ],\r\n",
      "        bbox_roi_extractor=dict(\r\n",
      "            featmap_strides=[\r\n",
      "                4,\r\n",
      "                8,\r\n",
      "                16,\r\n",
      "                32,\r\n",
      "            ],\r\n",
      "            out_channels=256,\r\n",
      "            roi_layer=dict(output_size=7, sampling_ratio=0, type='RoIAlign'),\r\n",
      "            type='SingleRoIExtractor'),\r\n",
      "        interleaved=True,\r\n",
      "        mask_head=[\r\n",
      "            dict(\r\n",
      "                conv_out_channels=256,\r\n",
      "                in_channels=256,\r\n",
      "                loss_mask=dict(\r\n",
      "                    loss_weight=1.0, type='CrossEntropyLoss', use_mask=True),\r\n",
      "                num_classes=80,\r\n",
      "                num_convs=4,\r\n",
      "                type='HTCMaskHead',\r\n",
      "                with_conv_res=False),\r\n",
      "            dict(\r\n",
      "                conv_out_channels=256,\r\n",
      "                in_channels=256,\r\n",
      "                loss_mask=dict(\r\n",
      "                    loss_weight=1.0, type='CrossEntropyLoss', use_mask=True),\r\n",
      "                num_classes=80,\r\n",
      "                num_convs=4,\r\n",
      "                type='HTCMaskHead'),\r\n",
      "            dict(\r\n",
      "                conv_out_channels=256,\r\n",
      "                in_channels=256,\r\n",
      "                loss_mask=dict(\r\n",
      "                    loss_weight=1.0, type='CrossEntropyLoss', use_mask=True),\r\n",
      "                num_classes=80,\r\n",
      "                num_convs=4,\r\n",
      "                type='HTCMaskHead'),\r\n",
      "        ],\r\n",
      "        mask_info_flow=True,\r\n",
      "        mask_roi_extractor=dict(\r\n",
      "            featmap_strides=[\r\n",
      "                4,\r\n",
      "                8,\r\n",
      "                16,\r\n",
      "                32,\r\n",
      "            ],\r\n",
      "            out_channels=256,\r\n",
      "            roi_layer=dict(output_size=14, sampling_ratio=0, type='RoIAlign'),\r\n",
      "            type='SingleRoIExtractor'),\r\n",
      "        num_stages=3,\r\n",
      "        semantic_head=dict(\r\n",
      "            conv_out_channels=256,\r\n",
      "            fusion_level=1,\r\n",
      "            in_channels=256,\r\n",
      "            loss_seg=dict(\r\n",
      "                ignore_index=255, loss_weight=0.2, type='CrossEntropyLoss'),\r\n",
      "            num_classes=183,\r\n",
      "            num_convs=4,\r\n",
      "            num_ins=5,\r\n",
      "            seg_scale_factor=0.125,\r\n",
      "            type='FusedSemanticHead'),\r\n",
      "        semantic_roi_extractor=dict(\r\n",
      "            featmap_strides=[\r\n",
      "                8,\r\n",
      "            ],\r\n",
      "            out_channels=256,\r\n",
      "            roi_layer=dict(output_size=14, sampling_ratio=0, type='RoIAlign'),\r\n",
      "            type='SingleRoIExtractor'),\r\n",
      "        stage_loss_weights=[\r\n",
      "            1,\r\n",
      "            0.5,\r\n",
      "            0.25,\r\n",
      "        ],\r\n",
      "        type='HybridTaskCascadeRoIHead'),\r\n",
      "    rpn_head=dict(\r\n",
      "        anchor_generator=dict(\r\n",
      "            ratios=[\r\n",
      "                0.5,\r\n",
      "                1.0,\r\n",
      "                2.0,\r\n",
      "            ],\r\n",
      "            scales=[\r\n",
      "                8,\r\n",
      "            ],\r\n",
      "            strides=[\r\n",
      "                4,\r\n",
      "                8,\r\n",
      "                16,\r\n",
      "                32,\r\n",
      "                64,\r\n",
      "            ],\r\n",
      "            type='AnchorGenerator'),\r\n",
      "        bbox_coder=dict(\r\n",
      "            target_means=[\r\n",
      "                0.0,\r\n",
      "                0.0,\r\n",
      "                0.0,\r\n",
      "                0.0,\r\n",
      "            ],\r\n",
      "            target_stds=[\r\n",
      "                1.0,\r\n",
      "                1.0,\r\n",
      "                1.0,\r\n",
      "                1.0,\r\n",
      "            ],\r\n",
      "            type='DeltaXYWHBBoxCoder'),\r\n",
      "        feat_channels=256,\r\n",
      "        in_channels=256,\r\n",
      "        loss_bbox=dict(\r\n",
      "            beta=0.1111111111111111, loss_weight=1.0, type='SmoothL1Loss'),\r\n",
      "        loss_cls=dict(\r\n",
      "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=True),\r\n",
      "        type='RPNHead'),\r\n",
      "    test_cfg=dict(\r\n",
      "        rcnn=dict(\r\n",
      "            mask_thr_binary=0.5,\r\n",
      "            max_per_img=100,\r\n",
      "            nms=dict(iou_threshold=0.5, type='nms'),\r\n",
      "            score_thr=0.001),\r\n",
      "        rpn=dict(\r\n",
      "            max_per_img=1000,\r\n",
      "            min_bbox_size=0,\r\n",
      "            nms=dict(iou_threshold=0.7, type='nms'),\r\n",
      "            nms_pre=1000)),\r\n",
      "    train_cfg=dict(\r\n",
      "        rcnn=[\r\n",
      "            dict(\r\n",
      "                assigner=dict(\r\n",
      "                    ignore_iof_thr=-1,\r\n",
      "                    min_pos_iou=0.5,\r\n",
      "                    neg_iou_thr=0.5,\r\n",
      "                    pos_iou_thr=0.5,\r\n",
      "                    type='MaxIoUAssigner'),\r\n",
      "                debug=False,\r\n",
      "                mask_size=28,\r\n",
      "                pos_weight=-1,\r\n",
      "                sampler=dict(\r\n",
      "                    add_gt_as_proposals=True,\r\n",
      "                    neg_pos_ub=-1,\r\n",
      "                    num=512,\r\n",
      "                    pos_fraction=0.25,\r\n",
      "                    type='RandomSampler')),\r\n",
      "            dict(\r\n",
      "                assigner=dict(\r\n",
      "                    ignore_iof_thr=-1,\r\n",
      "                    min_pos_iou=0.6,\r\n",
      "                    neg_iou_thr=0.6,\r\n",
      "                    pos_iou_thr=0.6,\r\n",
      "                    type='MaxIoUAssigner'),\r\n",
      "                debug=False,\r\n",
      "                mask_size=28,\r\n",
      "                pos_weight=-1,\r\n",
      "                sampler=dict(\r\n",
      "                    add_gt_as_proposals=True,\r\n",
      "                    neg_pos_ub=-1,\r\n",
      "                    num=512,\r\n",
      "                    pos_fraction=0.25,\r\n",
      "                    type='RandomSampler')),\r\n",
      "            dict(\r\n",
      "                assigner=dict(\r\n",
      "                    ignore_iof_thr=-1,\r\n",
      "                    min_pos_iou=0.7,\r\n",
      "                    neg_iou_thr=0.7,\r\n",
      "                    pos_iou_thr=0.7,\r\n",
      "                    type='MaxIoUAssigner'),\r\n",
      "                debug=False,\r\n",
      "                mask_size=28,\r\n",
      "                pos_weight=-1,\r\n",
      "                sampler=dict(\r\n",
      "                    add_gt_as_proposals=True,\r\n",
      "                    neg_pos_ub=-1,\r\n",
      "                    num=512,\r\n",
      "                    pos_fraction=0.25,\r\n",
      "                    type='RandomSampler')),\r\n",
      "        ],\r\n",
      "        rpn=dict(\r\n",
      "            allowed_border=0,\r\n",
      "            assigner=dict(\r\n",
      "                ignore_iof_thr=-1,\r\n",
      "                min_pos_iou=0.3,\r\n",
      "                neg_iou_thr=0.3,\r\n",
      "                pos_iou_thr=0.7,\r\n",
      "                type='MaxIoUAssigner'),\r\n",
      "            debug=False,\r\n",
      "            pos_weight=-1,\r\n",
      "            sampler=dict(\r\n",
      "                add_gt_as_proposals=False,\r\n",
      "                neg_pos_ub=-1,\r\n",
      "                num=256,\r\n",
      "                pos_fraction=0.5,\r\n",
      "                type='RandomSampler')),\r\n",
      "        rpn_proposal=dict(\r\n",
      "            max_per_img=2000,\r\n",
      "            min_bbox_size=0,\r\n",
      "            nms=dict(iou_threshold=0.7, type='nms'),\r\n",
      "            nms_pre=2000)),\r\n",
      "    type='HybridTaskCascade')\r\n",
      "optim_wrapper = dict(\r\n",
      "    optimizer=dict(lr=0.02, momentum=0.9, type='SGD', weight_decay=0.0001),\r\n",
      "    type='OptimWrapper')\r\n",
      "param_scheduler = [\r\n",
      "    dict(\r\n",
      "        begin=0, by_epoch=False, end=500, start_factor=0.001, type='LinearLR'),\r\n",
      "    dict(\r\n",
      "        begin=0,\r\n",
      "        by_epoch=True,\r\n",
      "        end=20,\r\n",
      "        gamma=0.1,\r\n",
      "        milestones=[\r\n",
      "            16,\r\n",
      "            19,\r\n",
      "        ],\r\n",
      "        type='MultiStepLR'),\r\n",
      "]\r\n",
      "resume = False\r\n",
      "test_cfg = dict(type='TestLoop')\r\n",
      "test_dataloader = dict(\r\n",
      "    batch_size=1,\r\n",
      "    dataset=dict(\r\n",
      "        ann_file='annotations/instances_val2017.json',\r\n",
      "        backend_args=None,\r\n",
      "        data_prefix=dict(img='val2017/'),\r\n",
      "        data_root='data/coco/',\r\n",
      "        pipeline=[\r\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "            dict(keep_ratio=True, scale=(\r\n",
      "                1333,\r\n",
      "                800,\r\n",
      "            ), type='Resize'),\r\n",
      "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\r\n",
      "            dict(\r\n",
      "                meta_keys=(\r\n",
      "                    'img_id',\r\n",
      "                    'img_path',\r\n",
      "                    'ori_shape',\r\n",
      "                    'img_shape',\r\n",
      "                    'scale_factor',\r\n",
      "                ),\r\n",
      "                type='PackDetInputs'),\r\n",
      "        ],\r\n",
      "        test_mode=True,\r\n",
      "        type='CocoDataset'),\r\n",
      "    drop_last=False,\r\n",
      "    num_workers=2,\r\n",
      "    persistent_workers=True,\r\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\r\n",
      "test_evaluator = dict(\r\n",
      "    ann_file='data/coco/annotations/instances_val2017.json',\r\n",
      "    backend_args=None,\r\n",
      "    format_only=False,\r\n",
      "    metric=[\r\n",
      "        'bbox',\r\n",
      "        'segm',\r\n",
      "    ],\r\n",
      "    type='CocoMetric')\r\n",
      "test_pipeline = [\r\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "    dict(keep_ratio=True, scale=(\r\n",
      "        1333,\r\n",
      "        800,\r\n",
      "    ), type='Resize'),\r\n",
      "    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\r\n",
      "    dict(\r\n",
      "        meta_keys=(\r\n",
      "            'img_id',\r\n",
      "            'img_path',\r\n",
      "            'ori_shape',\r\n",
      "            'img_shape',\r\n",
      "            'scale_factor',\r\n",
      "        ),\r\n",
      "        type='PackDetInputs'),\r\n",
      "]\r\n",
      "train_cfg = dict(max_epochs=20, type='EpochBasedTrainLoop', val_interval=1)\r\n",
      "train_dataloader = dict(\r\n",
      "    batch_sampler=dict(type='AspectRatioBatchSampler'),\r\n",
      "    batch_size=2,\r\n",
      "    dataset=dict(\r\n",
      "        ann_file='annotations/instances_train2017.json',\r\n",
      "        backend_args=None,\r\n",
      "        data_prefix=dict(img='train2017/', seg='stuffthingmaps/train2017/'),\r\n",
      "        data_root='data/coco/',\r\n",
      "        filter_cfg=dict(filter_empty_gt=True, min_size=32),\r\n",
      "        pipeline=[\r\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "            dict(\r\n",
      "                type='LoadAnnotations',\r\n",
      "                with_bbox=True,\r\n",
      "                with_mask=True,\r\n",
      "                with_seg=True),\r\n",
      "            dict(keep_ratio=True, scale=(\r\n",
      "                1333,\r\n",
      "                800,\r\n",
      "            ), type='Resize'),\r\n",
      "            dict(prob=0.5, type='RandomFlip'),\r\n",
      "            dict(type='PackDetInputs'),\r\n",
      "        ],\r\n",
      "        type='CocoDataset'),\r\n",
      "    num_workers=2,\r\n",
      "    persistent_workers=True,\r\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\r\n",
      "train_pipeline = [\r\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "    dict(\r\n",
      "        type='LoadAnnotations', with_bbox=True, with_mask=True, with_seg=True),\r\n",
      "    dict(keep_ratio=True, scale=(\r\n",
      "        1333,\r\n",
      "        800,\r\n",
      "    ), type='Resize'),\r\n",
      "    dict(prob=0.5, type='RandomFlip'),\r\n",
      "    dict(type='PackDetInputs'),\r\n",
      "]\r\n",
      "val_cfg = dict(type='ValLoop')\r\n",
      "val_dataloader = dict(\r\n",
      "    batch_size=1,\r\n",
      "    dataset=dict(\r\n",
      "        ann_file='annotations/instances_val2017.json',\r\n",
      "        backend_args=None,\r\n",
      "        data_prefix=dict(img='val2017/'),\r\n",
      "        data_root='data/coco/',\r\n",
      "        pipeline=[\r\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "            dict(keep_ratio=True, scale=(\r\n",
      "                1333,\r\n",
      "                800,\r\n",
      "            ), type='Resize'),\r\n",
      "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\r\n",
      "            dict(\r\n",
      "                meta_keys=(\r\n",
      "                    'img_id',\r\n",
      "                    'img_path',\r\n",
      "                    'ori_shape',\r\n",
      "                    'img_shape',\r\n",
      "                    'scale_factor',\r\n",
      "                ),\r\n",
      "                type='PackDetInputs'),\r\n",
      "        ],\r\n",
      "        test_mode=True,\r\n",
      "        type='CocoDataset'),\r\n",
      "    drop_last=False,\r\n",
      "    num_workers=2,\r\n",
      "    persistent_workers=True,\r\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\r\n",
      "val_evaluator = dict(\r\n",
      "    ann_file='data/coco/annotations/instances_val2017.json',\r\n",
      "    backend_args=None,\r\n",
      "    format_only=False,\r\n",
      "    metric=[\r\n",
      "        'bbox',\r\n",
      "        'segm',\r\n",
      "    ],\r\n",
      "    type='CocoMetric')\r\n",
      "vis_backends = [\r\n",
      "    dict(type='LocalVisBackend'),\r\n",
      "]\r\n",
      "visualizer = dict(\r\n",
      "    name='visualizer',\r\n",
      "    type='DetLocalVisualizer',\r\n",
      "    vis_backends=[\r\n",
      "        dict(type='LocalVisBackend'),\r\n",
      "    ])\r\n",
      "work_dir = './work_dirs/detectors_htc-r101_20e_coco'\r\n",
      "\r\n",
      "/mnt/ntfs/SSD1/_Master6/RM/mmdetection/mmdet/models/losses/cross_entropy_loss.py:240: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\r\n",
      "  warnings.warn(\r\n",
      "05/11 00:57:02 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\r\n",
      "05/11 00:57:02 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Hooks will be executed in the following order:\r\n",
      "before_run:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "before_train:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "before_train_epoch:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(NORMAL      ) DistSamplerSeedHook                \r\n",
      " -------------------- \r\n",
      "before_train_iter:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_train_iter:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      "(LOW         ) ParamSchedulerHook                 \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "after_train_epoch:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(LOW         ) ParamSchedulerHook                 \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "before_val:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "before_val_epoch:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "before_val_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_val_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(NORMAL      ) DetVisualizationHook               \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "after_val_epoch:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      "(LOW         ) ParamSchedulerHook                 \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "after_val:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "after_train:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "before_test:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "before_test_epoch:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "before_test_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_test_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(NORMAL      ) DetVisualizationHook               \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "after_test_epoch:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "after_test:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "after_run:\r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "loading annotations into memory...\r\n",
      "Done (t=0.58s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "loading annotations into memory...\r\n",
      "Done (t=0.41s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "Loads checkpoint by local backend from path: checkpoints/detectors_htc_r101_20e_coco_20210419_203638-348d533b.pth\r\n",
      "05/11 00:57:04 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Load checkpoint from checkpoints/detectors_htc_r101_20e_coco_20210419_203638-348d533b.pth\r\n",
      "/mnt/ntfs/SSD1/_Master6/RM/mmdetection/mmdet/models/roi_heads/mask_heads/fcn_mask_head.py:339: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\r\n",
      "  mask_preds = bboxes.new_tensor(mask_preds)\r\n",
      "05/11 00:57:21 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [  50/5000]    eta: 0:28:05  time: 0.3405  data_time: 0.0070  memory: 1437  \r\n",
      "05/11 00:57:37 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 100/5000]    eta: 0:26:26  time: 0.3072  data_time: 0.0034  memory: 1356  \r\n",
      "05/11 00:57:52 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 150/5000]    eta: 0:25:49  time: 0.3107  data_time: 0.0050  memory: 1369  \r\n",
      "05/11 00:58:07 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 200/5000]    eta: 0:25:06  time: 0.2969  data_time: 0.0032  memory: 1437  \r\n",
      "05/11 00:58:24 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 250/5000]    eta: 0:25:10  time: 0.3348  data_time: 0.0035  memory: 1355  \r\n",
      "05/11 00:58:39 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 300/5000]    eta: 0:24:35  time: 0.2941  data_time: 0.0034  memory: 1393  \r\n",
      "05/11 00:58:55 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 350/5000]    eta: 0:24:24  time: 0.3209  data_time: 0.0049  memory: 1437  \r\n",
      "05/11 00:59:10 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 400/5000]    eta: 0:24:05  time: 0.3089  data_time: 0.0036  memory: 1437  \r\n",
      "05/11 00:59:25 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 450/5000]    eta: 0:23:46  time: 0.3071  data_time: 0.0036  memory: 1340  \r\n",
      "05/11 00:59:41 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 500/5000]    eta: 0:23:29  time: 0.3107  data_time: 0.0050  memory: 1356  \r\n",
      "05/11 00:59:56 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 550/5000]    eta: 0:23:07  time: 0.2987  data_time: 0.0059  memory: 1369  \r\n",
      "05/11 01:00:12 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 600/5000]    eta: 0:22:54  time: 0.3190  data_time: 0.0047  memory: 1393  \r\n",
      "05/11 01:00:29 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 650/5000]    eta: 0:22:47  time: 0.3368  data_time: 0.0051  memory: 1402  \r\n",
      "05/11 01:00:45 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 700/5000]    eta: 0:22:35  time: 0.3254  data_time: 0.0044  memory: 1369  \r\n",
      "05/11 01:01:01 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 750/5000]    eta: 0:22:19  time: 0.3172  data_time: 0.0042  memory: 1393  \r\n",
      "05/11 01:01:16 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 800/5000]    eta: 0:21:59  time: 0.2971  data_time: 0.0040  memory: 1438  \r\n",
      "05/11 01:01:31 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 850/5000]    eta: 0:21:43  time: 0.3120  data_time: 0.0047  memory: 1388  \r\n",
      "05/11 01:01:47 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 900/5000]    eta: 0:21:25  time: 0.3034  data_time: 0.0039  memory: 1405  \r\n",
      "05/11 01:02:02 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 950/5000]    eta: 0:21:08  time: 0.3094  data_time: 0.0040  memory: 1340  \r\n",
      "05/11 01:02:17 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1000/5000]    eta: 0:20:51  time: 0.3047  data_time: 0.0036  memory: 1438  \r\n",
      "05/11 01:02:35 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1050/5000]    eta: 0:20:42  time: 0.3489  data_time: 0.0041  memory: 1355  \r\n",
      "05/11 01:02:51 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1100/5000]    eta: 0:20:29  time: 0.3338  data_time: 0.0046  memory: 1376  \r\n",
      "05/11 01:03:07 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1150/5000]    eta: 0:20:12  time: 0.3080  data_time: 0.0040  memory: 1437  \r\n",
      "05/11 01:03:25 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1200/5000]    eta: 0:20:03  time: 0.3563  data_time: 0.0040  memory: 1369  \r\n",
      "05/11 01:03:40 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1250/5000]    eta: 0:19:47  time: 0.3118  data_time: 0.0038  memory: 1428  \r\n",
      "05/11 01:03:56 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1300/5000]    eta: 0:19:31  time: 0.3190  data_time: 0.0037  memory: 1393  \r\n",
      "05/11 01:04:12 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1350/5000]    eta: 0:19:14  time: 0.3081  data_time: 0.0041  memory: 1393  \r\n",
      "05/11 01:04:27 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1400/5000]    eta: 0:18:57  time: 0.3060  data_time: 0.0037  memory: 1437  \r\n",
      "05/11 01:04:43 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1450/5000]    eta: 0:18:42  time: 0.3224  data_time: 0.0049  memory: 1416  \r\n",
      "05/11 01:04:58 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1500/5000]    eta: 0:18:25  time: 0.3057  data_time: 0.0039  memory: 1417  \r\n",
      "05/11 01:05:14 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1550/5000]    eta: 0:18:09  time: 0.3110  data_time: 0.0036  memory: 1369  \r\n",
      "05/11 01:05:29 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1600/5000]    eta: 0:17:52  time: 0.3028  data_time: 0.0031  memory: 1355  \r\n",
      "05/11 01:05:45 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1650/5000]    eta: 0:17:36  time: 0.3221  data_time: 0.0044  memory: 1393  \r\n",
      "05/11 01:06:01 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1700/5000]    eta: 0:17:22  time: 0.3283  data_time: 0.0036  memory: 1437  \r\n",
      "05/11 01:06:19 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1750/5000]    eta: 0:17:09  time: 0.3422  data_time: 0.0063  memory: 1379  \r\n",
      "05/11 01:06:34 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1800/5000]    eta: 0:16:52  time: 0.3057  data_time: 0.0041  memory: 1355  \r\n",
      "05/11 01:06:49 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1850/5000]    eta: 0:16:35  time: 0.3065  data_time: 0.0034  memory: 1369  \r\n",
      "05/11 01:07:05 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1900/5000]    eta: 0:16:19  time: 0.3155  data_time: 0.0051  memory: 1385  \r\n",
      "05/11 01:07:20 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1950/5000]    eta: 0:16:03  time: 0.3041  data_time: 0.0036  memory: 1369  \r\n",
      "05/11 01:07:35 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [2000/5000]    eta: 0:15:46  time: 0.3011  data_time: 0.0037  memory: 1371  \r\n",
      "05/11 01:07:50 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [2050/5000]    eta: 0:15:29  time: 0.3033  data_time: 0.0044  memory: 1393  \r\n",
      "05/11 01:08:06 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [2100/5000]    eta: 0:15:13  time: 0.3184  data_time: 0.0033  memory: 1393  \r\n",
      "05/11 01:08:22 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [2150/5000]    eta: 0:14:58  time: 0.3166  data_time: 0.0042  memory: 1393  \r\n",
      "05/11 01:08:37 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [2200/5000]    eta: 0:14:41  time: 0.3037  data_time: 0.0034  memory: 1393  \r\n",
      "05/11 01:08:53 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [2250/5000]    eta: 0:14:25  time: 0.3081  data_time: 0.0045  memory: 1370  \r\n",
      "05/11 01:09:08 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [2300/5000]    eta: 0:14:09  time: 0.3123  data_time: 0.0042  memory: 1432  \r\n",
      "05/11 01:09:23 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [2350/5000]    eta: 0:13:53  time: 0.3004  data_time: 0.0033  memory: 1437  \r\n",
      "05/11 01:09:39 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [2400/5000]    eta: 0:13:37  time: 0.3117  data_time: 0.0051  memory: 1355  \r\n",
      "05/11 01:09:54 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [2450/5000]    eta: 0:13:21  time: 0.3082  data_time: 0.0039  memory: 1437  \r\n",
      "05/11 01:10:09 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [2500/5000]    eta: 0:13:04  time: 0.2983  data_time: 0.0037  memory: 1393  \r\n",
      "05/11 01:10:25 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [2550/5000]    eta: 0:12:49  time: 0.3118  data_time: 0.0041  memory: 1437  \r\n",
      "05/11 01:10:41 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [2600/5000]    eta: 0:12:33  time: 0.3140  data_time: 0.0035  memory: 1437  \r\n",
      "05/11 01:10:56 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [2650/5000]    eta: 0:12:17  time: 0.3127  data_time: 0.0037  memory: 1437  \r\n",
      "05/11 01:11:12 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [2700/5000]    eta: 0:12:01  time: 0.3113  data_time: 0.0036  memory: 1369  \r\n",
      "05/11 01:11:27 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [2750/5000]    eta: 0:11:45  time: 0.3067  data_time: 0.0036  memory: 1369  \r\n",
      "05/11 01:11:43 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [2800/5000]    eta: 0:11:30  time: 0.3137  data_time: 0.0063  memory: 1434  \r\n",
      "05/11 01:11:58 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [2850/5000]    eta: 0:11:14  time: 0.3088  data_time: 0.0049  memory: 1436  \r\n",
      "05/11 01:12:13 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [2900/5000]    eta: 0:10:58  time: 0.3045  data_time: 0.0035  memory: 1435  \r\n",
      "05/11 01:12:29 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [2950/5000]    eta: 0:10:42  time: 0.3177  data_time: 0.0049  memory: 1393  \r\n",
      "05/11 01:12:45 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [3000/5000]    eta: 0:10:26  time: 0.3096  data_time: 0.0038  memory: 1393  \r\n",
      "05/11 01:13:01 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [3050/5000]    eta: 0:10:11  time: 0.3315  data_time: 0.0051  memory: 1393  \r\n",
      "05/11 01:13:19 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [3100/5000]    eta: 0:09:57  time: 0.3551  data_time: 0.0041  memory: 1369  \r\n",
      "05/11 01:13:36 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [3150/5000]    eta: 0:09:42  time: 0.3342  data_time: 0.0036  memory: 1393  \r\n",
      "05/11 01:13:53 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [3200/5000]    eta: 0:09:27  time: 0.3390  data_time: 0.0037  memory: 1380  \r\n",
      "05/11 01:14:09 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [3250/5000]    eta: 0:09:11  time: 0.3217  data_time: 0.0040  memory: 1410  \r\n",
      "05/11 01:14:24 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [3300/5000]    eta: 0:08:55  time: 0.3105  data_time: 0.0043  memory: 1369  \r\n",
      "05/11 01:14:41 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [3350/5000]    eta: 0:08:40  time: 0.3396  data_time: 0.0053  memory: 1437  \r\n",
      "05/11 01:14:58 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [3400/5000]    eta: 0:08:25  time: 0.3363  data_time: 0.0048  memory: 1344  \r\n",
      "05/11 01:15:14 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [3450/5000]    eta: 0:08:09  time: 0.3235  data_time: 0.0042  memory: 1393  \r\n",
      "05/11 01:15:30 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [3500/5000]    eta: 0:07:53  time: 0.3096  data_time: 0.0033  memory: 1393  \r\n",
      "05/11 01:15:45 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [3550/5000]    eta: 0:07:37  time: 0.3073  data_time: 0.0037  memory: 1393  \r\n",
      "05/11 01:16:01 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [3600/5000]    eta: 0:07:21  time: 0.3155  data_time: 0.0039  memory: 1355  \r\n",
      "05/11 01:16:16 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [3650/5000]    eta: 0:07:05  time: 0.3003  data_time: 0.0032  memory: 1369  \r\n",
      "05/11 01:16:32 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [3700/5000]    eta: 0:06:50  time: 0.3157  data_time: 0.0050  memory: 1437  \r\n",
      "05/11 01:16:47 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [3750/5000]    eta: 0:06:34  time: 0.3093  data_time: 0.0043  memory: 1393  \r\n",
      "05/11 01:17:03 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [3800/5000]    eta: 0:06:18  time: 0.3092  data_time: 0.0039  memory: 1356  \r\n",
      "05/11 01:17:19 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [3850/5000]    eta: 0:06:02  time: 0.3184  data_time: 0.0051  memory: 1393  \r\n",
      "05/11 01:17:34 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [3900/5000]    eta: 0:05:46  time: 0.3127  data_time: 0.0047  memory: 1366  \r\n",
      "05/11 01:17:50 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [3950/5000]    eta: 0:05:30  time: 0.3056  data_time: 0.0035  memory: 1380  \r\n",
      "05/11 01:18:05 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [4000/5000]    eta: 0:05:15  time: 0.3097  data_time: 0.0034  memory: 1412  \r\n",
      "05/11 01:18:21 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [4050/5000]    eta: 0:04:59  time: 0.3175  data_time: 0.0045  memory: 1355  \r\n",
      "05/11 01:18:36 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [4100/5000]    eta: 0:04:43  time: 0.3027  data_time: 0.0039  memory: 1393  \r\n",
      "05/11 01:18:51 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [4150/5000]    eta: 0:04:27  time: 0.3070  data_time: 0.0041  memory: 1343  \r\n",
      "05/11 01:19:07 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [4200/5000]    eta: 0:04:11  time: 0.3129  data_time: 0.0038  memory: 1340  \r\n",
      "05/11 01:19:22 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [4250/5000]    eta: 0:03:56  time: 0.3045  data_time: 0.0039  memory: 1393  \r\n",
      "05/11 01:19:38 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [4300/5000]    eta: 0:03:40  time: 0.3078  data_time: 0.0044  memory: 1345  \r\n",
      "05/11 01:19:53 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [4350/5000]    eta: 0:03:24  time: 0.3046  data_time: 0.0037  memory: 1387  \r\n",
      "05/11 01:20:09 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [4400/5000]    eta: 0:03:08  time: 0.3153  data_time: 0.0044  memory: 1437  \r\n",
      "05/11 01:20:25 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [4450/5000]    eta: 0:02:53  time: 0.3237  data_time: 0.0037  memory: 1437  \r\n",
      "05/11 01:20:41 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [4500/5000]    eta: 0:02:37  time: 0.3173  data_time: 0.0045  memory: 1414  \r\n",
      "05/11 01:20:57 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [4550/5000]    eta: 0:02:21  time: 0.3189  data_time: 0.0038  memory: 1424  \r\n",
      "05/11 01:21:12 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [4600/5000]    eta: 0:02:05  time: 0.3124  data_time: 0.0046  memory: 1437  \r\n",
      "05/11 01:21:29 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [4650/5000]    eta: 0:01:50  time: 0.3306  data_time: 0.0048  memory: 1387  \r\n",
      "05/11 01:21:45 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [4700/5000]    eta: 0:01:34  time: 0.3186  data_time: 0.0044  memory: 1355  \r\n",
      "05/11 01:22:00 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [4750/5000]    eta: 0:01:18  time: 0.3108  data_time: 0.0038  memory: 1437  \r\n",
      "05/11 01:22:16 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [4800/5000]    eta: 0:01:02  time: 0.3132  data_time: 0.0042  memory: 1369  \r\n",
      "05/11 01:22:31 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [4850/5000]    eta: 0:00:47  time: 0.3044  data_time: 0.0050  memory: 1369  \r\n",
      "05/11 01:22:47 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [4900/5000]    eta: 0:00:31  time: 0.3159  data_time: 0.0038  memory: 1437  \r\n",
      "05/11 01:23:03 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [4950/5000]    eta: 0:00:15  time: 0.3205  data_time: 0.0057  memory: 1403  \r\n",
      "05/11 01:23:20 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [5000/5000]    eta: 0:00:00  time: 0.3281  data_time: 0.0046  memory: 1393  \r\n",
      "05/11 01:23:30 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Evaluating bbox...\r\n",
      "Loading and preparing results...\r\n",
      "DONE (t=0.72s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "Running per image evaluation...\r\n",
      "Evaluate annotation type *bbox*\r\n",
      "DONE (t=23.45s).\r\n",
      "Accumulating evaluation results...\r\n",
      "DONE (t=5.77s).\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.505\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.693\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.553\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.314\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.545\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.668\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.653\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.653\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.653\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.474\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.696\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.811\r\n",
      "05/11 01:24:01 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - bbox_mAP_copypaste: 0.505 0.693 0.553 0.314 0.545 0.668\r\n",
      "05/11 01:24:01 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Evaluating segm...\r\n",
      "Loading and preparing results...\r\n",
      "DONE (t=2.26s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "Running per image evaluation...\r\n",
      "Evaluate annotation type *segm*\r\n",
      "DONE (t=28.37s).\r\n",
      "Accumulating evaluation results...\r\n",
      "DONE (t=5.00s).\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.438\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.666\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.476\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.224\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.471\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.634\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.574\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.574\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.574\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.387\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.616\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.740\r\n",
      "05/11 01:24:40 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - segm_mAP_copypaste: 0.438 0.666 0.476 0.224 0.471 0.634\r\n",
      "05/11 01:24:41 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [5000/5000]    coco/bbox_mAP: 0.5050  coco/bbox_mAP_50: 0.6930  coco/bbox_mAP_75: 0.5530  coco/bbox_mAP_s: 0.3140  coco/bbox_mAP_m: 0.5450  coco/bbox_mAP_l: 0.6680  coco/segm_mAP: 0.4380  coco/segm_mAP_50: 0.6660  coco/segm_mAP_75: 0.4760  coco/segm_mAP_s: 0.2240  coco/segm_mAP_m: 0.4710  coco/segm_mAP_l: 0.6340  data_time: 0.0042  time: 0.3150\r\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# DINO",
   "id": "a49eb3012d268f07"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T22:53:07.446937Z",
     "start_time": "2024-05-10T22:14:09.818779Z"
    }
   },
   "cell_type": "code",
   "source": "!python tools/test.py configs/dino/dino-5scale_swin-l_8xb2-36e_coco.py checkpoints/dino-5scale_swin-l_8xb2-36e_coco-5486e051.pth",
   "id": "5b9eeb546fea8f4a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/11 00:14:12 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - \r\n",
      "------------------------------------------------------------\r\n",
      "System environment:\r\n",
      "    sys.platform: linux\r\n",
      "    Python: 3.11.9 (main, Apr 17 2024, 00:00:00) [GCC 13.2.1 20240316 (Red Hat 13.2.1-7)]\r\n",
      "    CUDA available: True\r\n",
      "    MUSA available: False\r\n",
      "    numpy_random_seed: 366854277\r\n",
      "    GPU 0: NVIDIA GeForce RTX 3070\r\n",
      "    CUDA_HOME: /usr/local/cuda\r\n",
      "    NVCC: Cuda compilation tools, release 12.4, V12.4.131\r\n",
      "    GCC: gcc (GCC) 13.2.1 20240316 (Red Hat 13.2.1-7)\r\n",
      "    PyTorch: 2.1.0+cu121\r\n",
      "    PyTorch compiling details: PyTorch built with:\r\n",
      "  - GCC 9.3\r\n",
      "  - C++ Version: 201703\r\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\r\n",
      "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\r\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\r\n",
      "  - LAPACK is enabled (usually provided by MKL)\r\n",
      "  - NNPACK is enabled\r\n",
      "  - CPU capability usage: AVX2\r\n",
      "  - CUDA Runtime 12.1\r\n",
      "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\r\n",
      "  - CuDNN 8.9.2\r\n",
      "  - Magma 2.6.1\r\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \r\n",
      "\r\n",
      "    TorchVision: 0.16.0+cu121\r\n",
      "    OpenCV: 4.9.0\r\n",
      "    MMEngine: 0.10.4\r\n",
      "\r\n",
      "Runtime environment:\r\n",
      "    cudnn_benchmark: False\r\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\r\n",
      "    dist_cfg: {'backend': 'nccl'}\r\n",
      "    seed: 366854277\r\n",
      "    Distributed launcher: none\r\n",
      "    Distributed training: False\r\n",
      "    GPU number: 1\r\n",
      "------------------------------------------------------------\r\n",
      "\r\n",
      "05/11 00:14:13 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Config:\r\n",
      "auto_scale_lr = dict(base_batch_size=16)\r\n",
      "backend_args = None\r\n",
      "data_root = 'data/coco/'\r\n",
      "dataset_type = 'CocoDataset'\r\n",
      "default_hooks = dict(\r\n",
      "    checkpoint=dict(interval=1, type='CheckpointHook'),\r\n",
      "    logger=dict(interval=50, type='LoggerHook'),\r\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\r\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\r\n",
      "    timer=dict(type='IterTimerHook'),\r\n",
      "    visualization=dict(type='DetVisualizationHook'))\r\n",
      "default_scope = 'mmdet'\r\n",
      "env_cfg = dict(\r\n",
      "    cudnn_benchmark=False,\r\n",
      "    dist_cfg=dict(backend='nccl'),\r\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\r\n",
      "launcher = 'none'\r\n",
      "load_from = 'checkpoints/dino-5scale_swin-l_8xb2-36e_coco-5486e051.pth'\r\n",
      "log_level = 'INFO'\r\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\r\n",
      "max_epochs = 36\r\n",
      "model = dict(\r\n",
      "    as_two_stage=True,\r\n",
      "    backbone=dict(\r\n",
      "        attn_drop_rate=0.0,\r\n",
      "        convert_weights=True,\r\n",
      "        depths=[\r\n",
      "            2,\r\n",
      "            2,\r\n",
      "            18,\r\n",
      "            2,\r\n",
      "        ],\r\n",
      "        drop_path_rate=0.2,\r\n",
      "        drop_rate=0.0,\r\n",
      "        embed_dims=192,\r\n",
      "        init_cfg=dict(\r\n",
      "            checkpoint=\r\n",
      "            'https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_large_patch4_window12_384_22k.pth',\r\n",
      "            type='Pretrained'),\r\n",
      "        mlp_ratio=4,\r\n",
      "        num_heads=[\r\n",
      "            6,\r\n",
      "            12,\r\n",
      "            24,\r\n",
      "            48,\r\n",
      "        ],\r\n",
      "        out_indices=(\r\n",
      "            0,\r\n",
      "            1,\r\n",
      "            2,\r\n",
      "            3,\r\n",
      "        ),\r\n",
      "        patch_norm=True,\r\n",
      "        pretrain_img_size=384,\r\n",
      "        qk_scale=None,\r\n",
      "        qkv_bias=True,\r\n",
      "        type='SwinTransformer',\r\n",
      "        window_size=12,\r\n",
      "        with_cp=True),\r\n",
      "    bbox_head=dict(\r\n",
      "        loss_bbox=dict(loss_weight=5.0, type='L1Loss'),\r\n",
      "        loss_cls=dict(\r\n",
      "            alpha=0.25,\r\n",
      "            gamma=2.0,\r\n",
      "            loss_weight=1.0,\r\n",
      "            type='FocalLoss',\r\n",
      "            use_sigmoid=True),\r\n",
      "        loss_iou=dict(loss_weight=2.0, type='GIoULoss'),\r\n",
      "        num_classes=80,\r\n",
      "        sync_cls_avg_factor=True,\r\n",
      "        type='DINOHead'),\r\n",
      "    data_preprocessor=dict(\r\n",
      "        bgr_to_rgb=True,\r\n",
      "        mean=[\r\n",
      "            123.675,\r\n",
      "            116.28,\r\n",
      "            103.53,\r\n",
      "        ],\r\n",
      "        pad_size_divisor=1,\r\n",
      "        std=[\r\n",
      "            58.395,\r\n",
      "            57.12,\r\n",
      "            57.375,\r\n",
      "        ],\r\n",
      "        type='DetDataPreprocessor'),\r\n",
      "    decoder=dict(\r\n",
      "        layer_cfg=dict(\r\n",
      "            cross_attn_cfg=dict(dropout=0.0, embed_dims=256, num_levels=5),\r\n",
      "            ffn_cfg=dict(\r\n",
      "                embed_dims=256, feedforward_channels=2048, ffn_drop=0.0),\r\n",
      "            self_attn_cfg=dict(dropout=0.0, embed_dims=256, num_heads=8)),\r\n",
      "        num_layers=6,\r\n",
      "        post_norm_cfg=None,\r\n",
      "        return_intermediate=True),\r\n",
      "    dn_cfg=dict(\r\n",
      "        box_noise_scale=1.0,\r\n",
      "        group_cfg=dict(dynamic=True, num_dn_queries=100, num_groups=None),\r\n",
      "        label_noise_scale=0.5),\r\n",
      "    encoder=dict(\r\n",
      "        layer_cfg=dict(\r\n",
      "            ffn_cfg=dict(\r\n",
      "                embed_dims=256, feedforward_channels=2048, ffn_drop=0.0),\r\n",
      "            self_attn_cfg=dict(dropout=0.0, embed_dims=256, num_levels=5)),\r\n",
      "        num_layers=6),\r\n",
      "    neck=dict(\r\n",
      "        act_cfg=None,\r\n",
      "        in_channels=[\r\n",
      "            192,\r\n",
      "            384,\r\n",
      "            768,\r\n",
      "            1536,\r\n",
      "        ],\r\n",
      "        kernel_size=1,\r\n",
      "        norm_cfg=dict(num_groups=32, type='GN'),\r\n",
      "        num_outs=5,\r\n",
      "        out_channels=256,\r\n",
      "        type='ChannelMapper'),\r\n",
      "    num_feature_levels=5,\r\n",
      "    num_queries=900,\r\n",
      "    positional_encoding=dict(\r\n",
      "        normalize=True, num_feats=128, offset=0.0, temperature=20),\r\n",
      "    test_cfg=dict(max_per_img=300),\r\n",
      "    train_cfg=dict(\r\n",
      "        assigner=dict(\r\n",
      "            match_costs=[\r\n",
      "                dict(type='FocalLossCost', weight=2.0),\r\n",
      "                dict(box_format='xywh', type='BBoxL1Cost', weight=5.0),\r\n",
      "                dict(iou_mode='giou', type='IoUCost', weight=2.0),\r\n",
      "            ],\r\n",
      "            type='HungarianAssigner')),\r\n",
      "    type='DINO',\r\n",
      "    with_box_refine=True)\r\n",
      "num_levels = 5\r\n",
      "optim_wrapper = dict(\r\n",
      "    clip_grad=dict(max_norm=0.1, norm_type=2),\r\n",
      "    optimizer=dict(lr=0.0001, type='AdamW', weight_decay=0.0001),\r\n",
      "    paramwise_cfg=dict(custom_keys=dict(backbone=dict(lr_mult=0.1))),\r\n",
      "    type='OptimWrapper')\r\n",
      "param_scheduler = [\r\n",
      "    dict(\r\n",
      "        begin=0,\r\n",
      "        by_epoch=True,\r\n",
      "        end=36,\r\n",
      "        gamma=0.1,\r\n",
      "        milestones=[\r\n",
      "            27,\r\n",
      "            33,\r\n",
      "        ],\r\n",
      "        type='MultiStepLR'),\r\n",
      "]\r\n",
      "pretrained = 'https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_large_patch4_window12_384_22k.pth'\r\n",
      "resume = False\r\n",
      "test_cfg = dict(type='TestLoop')\r\n",
      "test_dataloader = dict(\r\n",
      "    batch_size=1,\r\n",
      "    dataset=dict(\r\n",
      "        ann_file='annotations/instances_val2017.json',\r\n",
      "        backend_args=None,\r\n",
      "        data_prefix=dict(img='val2017/'),\r\n",
      "        data_root='data/coco/',\r\n",
      "        pipeline=[\r\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "            dict(keep_ratio=True, scale=(\r\n",
      "                1333,\r\n",
      "                800,\r\n",
      "            ), type='Resize'),\r\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\r\n",
      "            dict(\r\n",
      "                meta_keys=(\r\n",
      "                    'img_id',\r\n",
      "                    'img_path',\r\n",
      "                    'ori_shape',\r\n",
      "                    'img_shape',\r\n",
      "                    'scale_factor',\r\n",
      "                ),\r\n",
      "                type='PackDetInputs'),\r\n",
      "        ],\r\n",
      "        test_mode=True,\r\n",
      "        type='CocoDataset'),\r\n",
      "    drop_last=False,\r\n",
      "    num_workers=2,\r\n",
      "    persistent_workers=True,\r\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\r\n",
      "test_evaluator = dict(\r\n",
      "    ann_file='data/coco/annotations/instances_val2017.json',\r\n",
      "    backend_args=None,\r\n",
      "    format_only=False,\r\n",
      "    metric='bbox',\r\n",
      "    type='CocoMetric')\r\n",
      "test_pipeline = [\r\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "    dict(keep_ratio=True, scale=(\r\n",
      "        1333,\r\n",
      "        800,\r\n",
      "    ), type='Resize'),\r\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\r\n",
      "    dict(\r\n",
      "        meta_keys=(\r\n",
      "            'img_id',\r\n",
      "            'img_path',\r\n",
      "            'ori_shape',\r\n",
      "            'img_shape',\r\n",
      "            'scale_factor',\r\n",
      "        ),\r\n",
      "        type='PackDetInputs'),\r\n",
      "]\r\n",
      "train_cfg = dict(max_epochs=36, type='EpochBasedTrainLoop', val_interval=1)\r\n",
      "train_dataloader = dict(\r\n",
      "    batch_sampler=dict(type='AspectRatioBatchSampler'),\r\n",
      "    batch_size=2,\r\n",
      "    dataset=dict(\r\n",
      "        ann_file='annotations/instances_train2017.json',\r\n",
      "        backend_args=None,\r\n",
      "        data_prefix=dict(img='train2017/'),\r\n",
      "        data_root='data/coco/',\r\n",
      "        filter_cfg=dict(filter_empty_gt=False, min_size=32),\r\n",
      "        pipeline=[\r\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\r\n",
      "            dict(prob=0.5, type='RandomFlip'),\r\n",
      "            dict(\r\n",
      "                transforms=[\r\n",
      "                    [\r\n",
      "                        dict(\r\n",
      "                            keep_ratio=True,\r\n",
      "                            scales=[\r\n",
      "                                (\r\n",
      "                                    480,\r\n",
      "                                    1333,\r\n",
      "                                ),\r\n",
      "                                (\r\n",
      "                                    512,\r\n",
      "                                    1333,\r\n",
      "                                ),\r\n",
      "                                (\r\n",
      "                                    544,\r\n",
      "                                    1333,\r\n",
      "                                ),\r\n",
      "                                (\r\n",
      "                                    576,\r\n",
      "                                    1333,\r\n",
      "                                ),\r\n",
      "                                (\r\n",
      "                                    608,\r\n",
      "                                    1333,\r\n",
      "                                ),\r\n",
      "                                (\r\n",
      "                                    640,\r\n",
      "                                    1333,\r\n",
      "                                ),\r\n",
      "                                (\r\n",
      "                                    672,\r\n",
      "                                    1333,\r\n",
      "                                ),\r\n",
      "                                (\r\n",
      "                                    704,\r\n",
      "                                    1333,\r\n",
      "                                ),\r\n",
      "                                (\r\n",
      "                                    736,\r\n",
      "                                    1333,\r\n",
      "                                ),\r\n",
      "                                (\r\n",
      "                                    768,\r\n",
      "                                    1333,\r\n",
      "                                ),\r\n",
      "                                (\r\n",
      "                                    800,\r\n",
      "                                    1333,\r\n",
      "                                ),\r\n",
      "                            ],\r\n",
      "                            type='RandomChoiceResize'),\r\n",
      "                    ],\r\n",
      "                    [\r\n",
      "                        dict(\r\n",
      "                            keep_ratio=True,\r\n",
      "                            scales=[\r\n",
      "                                (\r\n",
      "                                    400,\r\n",
      "                                    4200,\r\n",
      "                                ),\r\n",
      "                                (\r\n",
      "                                    500,\r\n",
      "                                    4200,\r\n",
      "                                ),\r\n",
      "                                (\r\n",
      "                                    600,\r\n",
      "                                    4200,\r\n",
      "                                ),\r\n",
      "                            ],\r\n",
      "                            type='RandomChoiceResize'),\r\n",
      "                        dict(\r\n",
      "                            allow_negative_crop=True,\r\n",
      "                            crop_size=(\r\n",
      "                                384,\r\n",
      "                                600,\r\n",
      "                            ),\r\n",
      "                            crop_type='absolute_range',\r\n",
      "                            type='RandomCrop'),\r\n",
      "                        dict(\r\n",
      "                            keep_ratio=True,\r\n",
      "                            scales=[\r\n",
      "                                (\r\n",
      "                                    480,\r\n",
      "                                    1333,\r\n",
      "                                ),\r\n",
      "                                (\r\n",
      "                                    512,\r\n",
      "                                    1333,\r\n",
      "                                ),\r\n",
      "                                (\r\n",
      "                                    544,\r\n",
      "                                    1333,\r\n",
      "                                ),\r\n",
      "                                (\r\n",
      "                                    576,\r\n",
      "                                    1333,\r\n",
      "                                ),\r\n",
      "                                (\r\n",
      "                                    608,\r\n",
      "                                    1333,\r\n",
      "                                ),\r\n",
      "                                (\r\n",
      "                                    640,\r\n",
      "                                    1333,\r\n",
      "                                ),\r\n",
      "                                (\r\n",
      "                                    672,\r\n",
      "                                    1333,\r\n",
      "                                ),\r\n",
      "                                (\r\n",
      "                                    704,\r\n",
      "                                    1333,\r\n",
      "                                ),\r\n",
      "                                (\r\n",
      "                                    736,\r\n",
      "                                    1333,\r\n",
      "                                ),\r\n",
      "                                (\r\n",
      "                                    768,\r\n",
      "                                    1333,\r\n",
      "                                ),\r\n",
      "                                (\r\n",
      "                                    800,\r\n",
      "                                    1333,\r\n",
      "                                ),\r\n",
      "                            ],\r\n",
      "                            type='RandomChoiceResize'),\r\n",
      "                    ],\r\n",
      "                ],\r\n",
      "                type='RandomChoice'),\r\n",
      "            dict(type='PackDetInputs'),\r\n",
      "        ],\r\n",
      "        type='CocoDataset'),\r\n",
      "    num_workers=2,\r\n",
      "    persistent_workers=True,\r\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\r\n",
      "train_pipeline = [\r\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\r\n",
      "    dict(prob=0.5, type='RandomFlip'),\r\n",
      "    dict(\r\n",
      "        transforms=[\r\n",
      "            [\r\n",
      "                dict(\r\n",
      "                    keep_ratio=True,\r\n",
      "                    scales=[\r\n",
      "                        (\r\n",
      "                            480,\r\n",
      "                            1333,\r\n",
      "                        ),\r\n",
      "                        (\r\n",
      "                            512,\r\n",
      "                            1333,\r\n",
      "                        ),\r\n",
      "                        (\r\n",
      "                            544,\r\n",
      "                            1333,\r\n",
      "                        ),\r\n",
      "                        (\r\n",
      "                            576,\r\n",
      "                            1333,\r\n",
      "                        ),\r\n",
      "                        (\r\n",
      "                            608,\r\n",
      "                            1333,\r\n",
      "                        ),\r\n",
      "                        (\r\n",
      "                            640,\r\n",
      "                            1333,\r\n",
      "                        ),\r\n",
      "                        (\r\n",
      "                            672,\r\n",
      "                            1333,\r\n",
      "                        ),\r\n",
      "                        (\r\n",
      "                            704,\r\n",
      "                            1333,\r\n",
      "                        ),\r\n",
      "                        (\r\n",
      "                            736,\r\n",
      "                            1333,\r\n",
      "                        ),\r\n",
      "                        (\r\n",
      "                            768,\r\n",
      "                            1333,\r\n",
      "                        ),\r\n",
      "                        (\r\n",
      "                            800,\r\n",
      "                            1333,\r\n",
      "                        ),\r\n",
      "                    ],\r\n",
      "                    type='RandomChoiceResize'),\r\n",
      "            ],\r\n",
      "            [\r\n",
      "                dict(\r\n",
      "                    keep_ratio=True,\r\n",
      "                    scales=[\r\n",
      "                        (\r\n",
      "                            400,\r\n",
      "                            4200,\r\n",
      "                        ),\r\n",
      "                        (\r\n",
      "                            500,\r\n",
      "                            4200,\r\n",
      "                        ),\r\n",
      "                        (\r\n",
      "                            600,\r\n",
      "                            4200,\r\n",
      "                        ),\r\n",
      "                    ],\r\n",
      "                    type='RandomChoiceResize'),\r\n",
      "                dict(\r\n",
      "                    allow_negative_crop=True,\r\n",
      "                    crop_size=(\r\n",
      "                        384,\r\n",
      "                        600,\r\n",
      "                    ),\r\n",
      "                    crop_type='absolute_range',\r\n",
      "                    type='RandomCrop'),\r\n",
      "                dict(\r\n",
      "                    keep_ratio=True,\r\n",
      "                    scales=[\r\n",
      "                        (\r\n",
      "                            480,\r\n",
      "                            1333,\r\n",
      "                        ),\r\n",
      "                        (\r\n",
      "                            512,\r\n",
      "                            1333,\r\n",
      "                        ),\r\n",
      "                        (\r\n",
      "                            544,\r\n",
      "                            1333,\r\n",
      "                        ),\r\n",
      "                        (\r\n",
      "                            576,\r\n",
      "                            1333,\r\n",
      "                        ),\r\n",
      "                        (\r\n",
      "                            608,\r\n",
      "                            1333,\r\n",
      "                        ),\r\n",
      "                        (\r\n",
      "                            640,\r\n",
      "                            1333,\r\n",
      "                        ),\r\n",
      "                        (\r\n",
      "                            672,\r\n",
      "                            1333,\r\n",
      "                        ),\r\n",
      "                        (\r\n",
      "                            704,\r\n",
      "                            1333,\r\n",
      "                        ),\r\n",
      "                        (\r\n",
      "                            736,\r\n",
      "                            1333,\r\n",
      "                        ),\r\n",
      "                        (\r\n",
      "                            768,\r\n",
      "                            1333,\r\n",
      "                        ),\r\n",
      "                        (\r\n",
      "                            800,\r\n",
      "                            1333,\r\n",
      "                        ),\r\n",
      "                    ],\r\n",
      "                    type='RandomChoiceResize'),\r\n",
      "            ],\r\n",
      "        ],\r\n",
      "        type='RandomChoice'),\r\n",
      "    dict(type='PackDetInputs'),\r\n",
      "]\r\n",
      "val_cfg = dict(type='ValLoop')\r\n",
      "val_dataloader = dict(\r\n",
      "    batch_size=1,\r\n",
      "    dataset=dict(\r\n",
      "        ann_file='annotations/instances_val2017.json',\r\n",
      "        backend_args=None,\r\n",
      "        data_prefix=dict(img='val2017/'),\r\n",
      "        data_root='data/coco/',\r\n",
      "        pipeline=[\r\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "            dict(keep_ratio=True, scale=(\r\n",
      "                1333,\r\n",
      "                800,\r\n",
      "            ), type='Resize'),\r\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\r\n",
      "            dict(\r\n",
      "                meta_keys=(\r\n",
      "                    'img_id',\r\n",
      "                    'img_path',\r\n",
      "                    'ori_shape',\r\n",
      "                    'img_shape',\r\n",
      "                    'scale_factor',\r\n",
      "                ),\r\n",
      "                type='PackDetInputs'),\r\n",
      "        ],\r\n",
      "        test_mode=True,\r\n",
      "        type='CocoDataset'),\r\n",
      "    drop_last=False,\r\n",
      "    num_workers=2,\r\n",
      "    persistent_workers=True,\r\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\r\n",
      "val_evaluator = dict(\r\n",
      "    ann_file='data/coco/annotations/instances_val2017.json',\r\n",
      "    backend_args=None,\r\n",
      "    format_only=False,\r\n",
      "    metric='bbox',\r\n",
      "    type='CocoMetric')\r\n",
      "vis_backends = [\r\n",
      "    dict(type='LocalVisBackend'),\r\n",
      "]\r\n",
      "visualizer = dict(\r\n",
      "    name='visualizer',\r\n",
      "    type='DetLocalVisualizer',\r\n",
      "    vis_backends=[\r\n",
      "        dict(type='LocalVisBackend'),\r\n",
      "    ])\r\n",
      "work_dir = './work_dirs/dino-5scale_swin-l_8xb2-36e_coco'\r\n",
      "\r\n",
      "05/11 00:14:15 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\r\n",
      "05/11 00:14:15 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Hooks will be executed in the following order:\r\n",
      "before_run:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "before_train:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "before_train_epoch:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(NORMAL      ) DistSamplerSeedHook                \r\n",
      " -------------------- \r\n",
      "before_train_iter:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_train_iter:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      "(LOW         ) ParamSchedulerHook                 \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "after_train_epoch:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(LOW         ) ParamSchedulerHook                 \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "before_val:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "before_val_epoch:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "before_val_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_val_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(NORMAL      ) DetVisualizationHook               \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "after_val_epoch:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      "(LOW         ) ParamSchedulerHook                 \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "after_val:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "after_train:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "before_test:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "before_test_epoch:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "before_test_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_test_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(NORMAL      ) DetVisualizationHook               \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "after_test_epoch:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "after_test:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "after_run:\r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "loading annotations into memory...\r\n",
      "Done (t=0.63s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "loading annotations into memory...\r\n",
      "Done (t=0.40s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "Loads checkpoint by local backend from path: checkpoints/dino-5scale_swin-l_8xb2-36e_coco-5486e051.pth\r\n",
      "05/11 00:14:19 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Load checkpoint from checkpoints/dino-5scale_swin-l_8xb2-36e_coco-5486e051.pth\r\n",
      "/mnt/ntfs/SSD1/_Master6/RM/mmdetection/.venv/lib64/python3.11/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\r\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\r\n",
      "05/11 00:14:42 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [  50/5000]    eta: 0:38:09  time: 0.4626  data_time: 0.0029  memory: 2068  \r\n",
      "05/11 00:15:05 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 100/5000]    eta: 0:37:29  time: 0.4556  data_time: 0.0019  memory: 2037  \r\n",
      "05/11 00:15:28 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 150/5000]    eta: 0:37:03  time: 0.4573  data_time: 0.0025  memory: 2065  \r\n",
      "05/11 00:15:50 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 200/5000]    eta: 0:36:19  time: 0.4410  data_time: 0.0020  memory: 2028  \r\n",
      "05/11 00:16:14 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 250/5000]    eta: 0:36:13  time: 0.4713  data_time: 0.0022  memory: 2043  \r\n",
      "05/11 00:16:37 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 300/5000]    eta: 0:36:01  time: 0.4715  data_time: 0.0018  memory: 2054  \r\n",
      "05/11 00:16:59 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 350/5000]    eta: 0:35:21  time: 0.4341  data_time: 0.0021  memory: 2006  \r\n",
      "05/11 00:17:21 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 400/5000]    eta: 0:34:49  time: 0.4398  data_time: 0.0019  memory: 2083  \r\n",
      "05/11 00:17:43 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 450/5000]    eta: 0:34:22  time: 0.4456  data_time: 0.0021  memory: 2023  \r\n",
      "05/11 00:18:05 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 500/5000]    eta: 0:33:54  time: 0.4424  data_time: 0.0029  memory: 2037  \r\n",
      "05/11 00:18:29 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 550/5000]    eta: 0:33:36  time: 0.4624  data_time: 0.0019  memory: 2083  \r\n",
      "05/11 00:18:51 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 600/5000]    eta: 0:33:08  time: 0.4407  data_time: 0.0019  memory: 2068  \r\n",
      "05/11 00:19:13 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 650/5000]    eta: 0:32:43  time: 0.4438  data_time: 0.0025  memory: 2008  \r\n",
      "05/11 00:19:35 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 700/5000]    eta: 0:32:20  time: 0.4501  data_time: 0.0031  memory: 2083  \r\n",
      "05/11 00:19:57 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 750/5000]    eta: 0:31:55  time: 0.4412  data_time: 0.0021  memory: 2004  \r\n",
      "05/11 00:20:19 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 800/5000]    eta: 0:31:26  time: 0.4281  data_time: 0.0018  memory: 2083  \r\n",
      "05/11 00:20:43 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 850/5000]    eta: 0:31:13  time: 0.4883  data_time: 0.0020  memory: 2040  \r\n",
      "05/11 00:21:05 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 900/5000]    eta: 0:30:48  time: 0.4417  data_time: 0.0018  memory: 2023  \r\n",
      "05/11 00:21:28 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 950/5000]    eta: 0:30:27  time: 0.4563  data_time: 0.0019  memory: 2009  \r\n",
      "05/11 00:21:50 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1000/5000]    eta: 0:30:00  time: 0.4308  data_time: 0.0022  memory: 2008  \r\n",
      "05/11 00:22:12 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1050/5000]    eta: 0:29:37  time: 0.4446  data_time: 0.0022  memory: 2054  \r\n",
      "05/11 00:22:33 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1100/5000]    eta: 0:29:11  time: 0.4328  data_time: 0.0019  memory: 2066  \r\n",
      "05/11 00:22:56 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1150/5000]    eta: 0:28:48  time: 0.4413  data_time: 0.0026  memory: 2027  \r\n",
      "05/11 00:23:17 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1200/5000]    eta: 0:28:22  time: 0.4309  data_time: 0.0019  memory: 2083  \r\n",
      "05/11 00:23:41 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1250/5000]    eta: 0:28:03  time: 0.4694  data_time: 0.0019  memory: 2030  \r\n",
      "05/11 00:24:03 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1300/5000]    eta: 0:27:40  time: 0.4435  data_time: 0.0019  memory: 2083  \r\n",
      "05/11 00:24:25 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1350/5000]    eta: 0:27:18  time: 0.4530  data_time: 0.0026  memory: 2083  \r\n",
      "05/11 00:24:47 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1400/5000]    eta: 0:26:54  time: 0.4387  data_time: 0.0018  memory: 2040  \r\n",
      "05/11 00:25:09 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1450/5000]    eta: 0:26:30  time: 0.4325  data_time: 0.0019  memory: 2078  \r\n",
      "05/11 00:25:30 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1500/5000]    eta: 0:26:05  time: 0.4245  data_time: 0.0018  memory: 2030  \r\n",
      "05/11 00:25:54 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1550/5000]    eta: 0:25:46  time: 0.4759  data_time: 0.0018  memory: 2046  \r\n",
      "05/11 00:26:16 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1600/5000]    eta: 0:25:22  time: 0.4396  data_time: 0.0019  memory: 2060  \r\n",
      "05/11 00:26:38 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1650/5000]    eta: 0:24:59  time: 0.4353  data_time: 0.0018  memory: 2078  \r\n",
      "05/11 00:26:59 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1700/5000]    eta: 0:24:34  time: 0.4211  data_time: 0.0021  memory: 2013  \r\n",
      "05/11 00:27:21 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1750/5000]    eta: 0:24:10  time: 0.4382  data_time: 0.0019  memory: 2068  \r\n",
      "05/11 00:27:42 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1800/5000]    eta: 0:23:47  time: 0.4336  data_time: 0.0031  memory: 2004  \r\n",
      "05/11 00:28:04 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1850/5000]    eta: 0:23:24  time: 0.4375  data_time: 0.0030  memory: 2054  \r\n",
      "05/11 00:28:26 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1900/5000]    eta: 0:23:01  time: 0.4435  data_time: 0.0019  memory: 2066  \r\n",
      "05/11 00:28:48 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [1950/5000]    eta: 0:22:38  time: 0.4281  data_time: 0.0018  memory: 2054  \r\n",
      "05/11 00:29:10 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [2000/5000]    eta: 0:22:16  time: 0.4458  data_time: 0.0019  memory: 2080  \r\n",
      "05/11 00:29:32 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [2050/5000]    eta: 0:21:52  time: 0.4334  data_time: 0.0021  memory: 1986  \r\n",
      "05/11 00:29:53 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [2100/5000]    eta: 0:21:29  time: 0.4299  data_time: 0.0021  memory: 2054  \r\n",
      "05/11 00:30:15 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [2150/5000]    eta: 0:21:07  time: 0.4420  data_time: 0.0019  memory: 2009  \r\n",
      "05/11 00:30:37 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [2200/5000]    eta: 0:20:43  time: 0.4250  data_time: 0.0020  memory: 2008  \r\n",
      "05/11 00:30:59 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [2250/5000]    eta: 0:20:21  time: 0.4429  data_time: 0.0019  memory: 2054  \r\n",
      "05/11 00:31:22 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [2300/5000]    eta: 0:19:59  time: 0.4547  data_time: 0.0025  memory: 1962  \r\n",
      "05/11 00:31:44 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [2350/5000]    eta: 0:19:38  time: 0.4577  data_time: 0.0020  memory: 2008  \r\n",
      "05/11 00:32:07 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [2400/5000]    eta: 0:19:16  time: 0.4461  data_time: 0.0019  memory: 2054  \r\n",
      "05/11 00:32:29 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [2450/5000]    eta: 0:18:54  time: 0.4463  data_time: 0.0019  memory: 2037  \r\n",
      "05/11 00:32:51 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [2500/5000]    eta: 0:18:31  time: 0.4406  data_time: 0.0019  memory: 2072  \r\n",
      "05/11 00:33:14 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [2550/5000]    eta: 0:18:09  time: 0.4510  data_time: 0.0018  memory: 2046  \r\n",
      "05/11 00:33:36 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [2600/5000]    eta: 0:17:47  time: 0.4453  data_time: 0.0018  memory: 2083  \r\n",
      "05/11 00:34:00 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [2650/5000]    eta: 0:17:27  time: 0.4891  data_time: 0.0019  memory: 2008  \r\n",
      "05/11 00:34:22 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [2700/5000]    eta: 0:17:04  time: 0.4381  data_time: 0.0019  memory: 2079  \r\n",
      "05/11 00:34:45 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [2750/5000]    eta: 0:16:42  time: 0.4449  data_time: 0.0021  memory: 2083  \r\n",
      "05/11 00:35:06 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [2800/5000]    eta: 0:16:19  time: 0.4389  data_time: 0.0019  memory: 2083  \r\n",
      "05/11 00:35:28 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [2850/5000]    eta: 0:15:57  time: 0.4362  data_time: 0.0019  memory: 2021  \r\n",
      "05/11 00:35:50 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [2900/5000]    eta: 0:15:34  time: 0.4430  data_time: 0.0021  memory: 2058  \r\n",
      "05/11 00:36:12 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [2950/5000]    eta: 0:15:12  time: 0.4389  data_time: 0.0018  memory: 2083  \r\n",
      "05/11 00:36:34 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [3000/5000]    eta: 0:14:49  time: 0.4374  data_time: 0.0024  memory: 2054  \r\n",
      "05/11 00:36:56 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [3050/5000]    eta: 0:14:27  time: 0.4421  data_time: 0.0019  memory: 2083  \r\n",
      "05/11 00:37:19 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [3100/5000]    eta: 0:14:05  time: 0.4480  data_time: 0.0019  memory: 2065  \r\n",
      "05/11 00:37:41 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [3150/5000]    eta: 0:13:42  time: 0.4400  data_time: 0.0020  memory: 2017  \r\n",
      "05/11 00:38:03 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [3200/5000]    eta: 0:13:20  time: 0.4458  data_time: 0.0018  memory: 2083  \r\n",
      "05/11 00:38:25 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [3250/5000]    eta: 0:12:58  time: 0.4323  data_time: 0.0018  memory: 1972  \r\n",
      "05/11 00:38:47 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [3300/5000]    eta: 0:12:35  time: 0.4379  data_time: 0.0018  memory: 2078  \r\n",
      "05/11 00:39:08 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [3350/5000]    eta: 0:12:13  time: 0.4334  data_time: 0.0019  memory: 2071  \r\n",
      "05/11 00:39:31 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [3400/5000]    eta: 0:11:51  time: 0.4460  data_time: 0.0021  memory: 2016  \r\n",
      "05/11 00:39:53 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [3450/5000]    eta: 0:11:28  time: 0.4430  data_time: 0.0019  memory: 2071  \r\n",
      "05/11 00:40:14 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [3500/5000]    eta: 0:11:06  time: 0.4351  data_time: 0.0020  memory: 2083  \r\n",
      "05/11 00:40:36 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [3550/5000]    eta: 0:10:44  time: 0.4366  data_time: 0.0018  memory: 2057  \r\n",
      "05/11 00:40:58 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [3600/5000]    eta: 0:10:21  time: 0.4423  data_time: 0.0023  memory: 2046  \r\n",
      "05/11 00:41:20 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [3650/5000]    eta: 0:09:59  time: 0.4413  data_time: 0.0018  memory: 2042  \r\n",
      "05/11 00:41:42 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [3700/5000]    eta: 0:09:37  time: 0.4376  data_time: 0.0019  memory: 1965  \r\n",
      "05/11 00:42:04 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [3750/5000]    eta: 0:09:14  time: 0.4401  data_time: 0.0021  memory: 2009  \r\n",
      "05/11 00:42:27 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [3800/5000]    eta: 0:08:52  time: 0.4447  data_time: 0.0024  memory: 2040  \r\n",
      "05/11 00:42:49 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [3850/5000]    eta: 0:08:30  time: 0.4450  data_time: 0.0018  memory: 2083  \r\n",
      "05/11 00:43:12 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [3900/5000]    eta: 0:08:08  time: 0.4555  data_time: 0.0019  memory: 2023  \r\n",
      "05/11 00:43:34 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [3950/5000]    eta: 0:07:46  time: 0.4399  data_time: 0.0018  memory: 2023  \r\n",
      "05/11 00:43:56 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [4000/5000]    eta: 0:07:24  time: 0.4417  data_time: 0.0019  memory: 1994  \r\n",
      "05/11 00:44:18 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [4050/5000]    eta: 0:07:01  time: 0.4417  data_time: 0.0028  memory: 2046  \r\n",
      "05/11 00:44:40 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [4100/5000]    eta: 0:06:39  time: 0.4400  data_time: 0.0023  memory: 2083  \r\n",
      "05/11 00:45:02 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [4150/5000]    eta: 0:06:17  time: 0.4380  data_time: 0.0020  memory: 1981  \r\n",
      "05/11 00:45:24 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [4200/5000]    eta: 0:05:55  time: 0.4387  data_time: 0.0018  memory: 2030  \r\n",
      "05/11 00:45:45 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [4250/5000]    eta: 0:05:32  time: 0.4236  data_time: 0.0018  memory: 2066  \r\n",
      "05/11 00:46:07 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [4300/5000]    eta: 0:05:10  time: 0.4349  data_time: 0.0024  memory: 2030  \r\n",
      "05/11 00:46:29 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [4350/5000]    eta: 0:04:48  time: 0.4395  data_time: 0.0025  memory: 2079  \r\n",
      "05/11 00:46:51 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [4400/5000]    eta: 0:04:26  time: 0.4454  data_time: 0.0023  memory: 2008  \r\n",
      "05/11 00:47:12 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [4450/5000]    eta: 0:04:03  time: 0.4289  data_time: 0.0018  memory: 2030  \r\n",
      "05/11 00:47:34 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [4500/5000]    eta: 0:03:41  time: 0.4343  data_time: 0.0018  memory: 2054  \r\n",
      "05/11 00:47:56 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [4550/5000]    eta: 0:03:19  time: 0.4472  data_time: 0.0027  memory: 2068  \r\n",
      "05/11 00:48:18 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [4600/5000]    eta: 0:02:57  time: 0.4343  data_time: 0.0022  memory: 2009  \r\n",
      "05/11 00:48:40 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [4650/5000]    eta: 0:02:35  time: 0.4401  data_time: 0.0024  memory: 1969  \r\n",
      "05/11 00:49:02 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [4700/5000]    eta: 0:02:12  time: 0.4383  data_time: 0.0019  memory: 2046  \r\n",
      "05/11 00:49:23 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [4750/5000]    eta: 0:01:50  time: 0.4150  data_time: 0.0018  memory: 2008  \r\n",
      "05/11 00:49:44 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [4800/5000]    eta: 0:01:28  time: 0.4218  data_time: 0.0018  memory: 2065  \r\n",
      "05/11 00:50:06 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [4850/5000]    eta: 0:01:06  time: 0.4353  data_time: 0.0019  memory: 2083  \r\n",
      "05/11 00:50:27 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [4900/5000]    eta: 0:00:44  time: 0.4314  data_time: 0.0018  memory: 2040  \r\n",
      "05/11 00:50:49 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [4950/5000]    eta: 0:00:22  time: 0.4393  data_time: 0.0025  memory: 2054  \r\n",
      "05/11 00:51:11 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [5000/5000]    eta: 0:00:00  time: 0.4413  data_time: 0.0019  memory: 2058  \r\n",
      "05/11 00:51:28 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Evaluating bbox...\r\n",
      "Loading and preparing results...\r\n",
      "DONE (t=3.31s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "Running per image evaluation...\r\n",
      "Evaluate annotation type *bbox*\r\n",
      "DONE (t=64.81s).\r\n",
      "Accumulating evaluation results...\r\n",
      "DONE (t=20.99s).\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.583\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.771\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.642\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.415\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.622\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.735\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.774\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.777\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.777\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.651\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.812\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.910\r\n",
      "05/11 00:53:04 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - bbox_mAP_copypaste: 0.583 0.771 0.642 0.415 0.622 0.735\r\n",
      "05/11 00:53:06 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [5000/5000]    coco/bbox_mAP: 0.5830  coco/bbox_mAP_50: 0.7710  coco/bbox_mAP_75: 0.6420  coco/bbox_mAP_s: 0.4150  coco/bbox_mAP_m: 0.6220  coco/bbox_mAP_l: 0.7350  data_time: 0.0021  time: 0.4423\r\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# YOLOX",
   "id": "fa0e60dffe337e58"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T21:55:19.304667Z",
     "start_time": "2024-05-10T21:51:56.728980Z"
    }
   },
   "cell_type": "code",
   "source": "!python tools/test.py configs/yolox/yolox_x_8xb8-300e_coco.py checkpoints/yolox_x.pth",
   "id": "ec852ab7a492bc91",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/10 23:51:59 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - \r\n",
      "------------------------------------------------------------\r\n",
      "System environment:\r\n",
      "    sys.platform: linux\r\n",
      "    Python: 3.11.9 (main, Apr 17 2024, 00:00:00) [GCC 13.2.1 20240316 (Red Hat 13.2.1-7)]\r\n",
      "    CUDA available: True\r\n",
      "    MUSA available: False\r\n",
      "    numpy_random_seed: 1946588213\r\n",
      "    GPU 0: NVIDIA GeForce RTX 3070\r\n",
      "    CUDA_HOME: /usr/local/cuda\r\n",
      "    NVCC: Cuda compilation tools, release 12.4, V12.4.131\r\n",
      "    GCC: gcc (GCC) 13.2.1 20240316 (Red Hat 13.2.1-7)\r\n",
      "    PyTorch: 2.1.0+cu121\r\n",
      "    PyTorch compiling details: PyTorch built with:\r\n",
      "  - GCC 9.3\r\n",
      "  - C++ Version: 201703\r\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\r\n",
      "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\r\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\r\n",
      "  - LAPACK is enabled (usually provided by MKL)\r\n",
      "  - NNPACK is enabled\r\n",
      "  - CPU capability usage: AVX2\r\n",
      "  - CUDA Runtime 12.1\r\n",
      "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\r\n",
      "  - CuDNN 8.9.2\r\n",
      "  - Magma 2.6.1\r\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \r\n",
      "\r\n",
      "    TorchVision: 0.16.0+cu121\r\n",
      "    OpenCV: 4.9.0\r\n",
      "    MMEngine: 0.10.4\r\n",
      "\r\n",
      "Runtime environment:\r\n",
      "    cudnn_benchmark: False\r\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\r\n",
      "    dist_cfg: {'backend': 'nccl'}\r\n",
      "    seed: 1946588213\r\n",
      "    Distributed launcher: none\r\n",
      "    Distributed training: False\r\n",
      "    GPU number: 1\r\n",
      "------------------------------------------------------------\r\n",
      "\r\n",
      "05/10 23:51:59 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Config:\r\n",
      "auto_scale_lr = dict(base_batch_size=64, enable=False)\r\n",
      "backend_args = None\r\n",
      "base_lr = 0.01\r\n",
      "custom_hooks = [\r\n",
      "    dict(num_last_epochs=15, priority=48, type='YOLOXModeSwitchHook'),\r\n",
      "    dict(priority=48, type='SyncNormHook'),\r\n",
      "    dict(\r\n",
      "        ema_type='ExpMomentumEMA',\r\n",
      "        momentum=0.0001,\r\n",
      "        priority=49,\r\n",
      "        type='EMAHook',\r\n",
      "        update_buffers=True),\r\n",
      "]\r\n",
      "data_root = 'data/coco/'\r\n",
      "dataset_type = 'CocoDataset'\r\n",
      "default_hooks = dict(\r\n",
      "    checkpoint=dict(interval=10, max_keep_ckpts=3, type='CheckpointHook'),\r\n",
      "    logger=dict(interval=50, type='LoggerHook'),\r\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\r\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\r\n",
      "    timer=dict(type='IterTimerHook'),\r\n",
      "    visualization=dict(type='DetVisualizationHook'))\r\n",
      "default_scope = 'mmdet'\r\n",
      "env_cfg = dict(\r\n",
      "    cudnn_benchmark=False,\r\n",
      "    dist_cfg=dict(backend='nccl'),\r\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\r\n",
      "img_scale = (\r\n",
      "    640,\r\n",
      "    640,\r\n",
      ")\r\n",
      "img_scales = [\r\n",
      "    (\r\n",
      "        640,\r\n",
      "        640,\r\n",
      "    ),\r\n",
      "    (\r\n",
      "        320,\r\n",
      "        320,\r\n",
      "    ),\r\n",
      "    (\r\n",
      "        960,\r\n",
      "        960,\r\n",
      "    ),\r\n",
      "]\r\n",
      "interval = 10\r\n",
      "launcher = 'none'\r\n",
      "load_from = 'checkpoints/yolox_x.pth'\r\n",
      "log_level = 'INFO'\r\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\r\n",
      "max_epochs = 300\r\n",
      "model = dict(\r\n",
      "    backbone=dict(\r\n",
      "        act_cfg=dict(type='Swish'),\r\n",
      "        deepen_factor=1.33,\r\n",
      "        norm_cfg=dict(eps=0.001, momentum=0.03, type='BN'),\r\n",
      "        out_indices=(\r\n",
      "            2,\r\n",
      "            3,\r\n",
      "            4,\r\n",
      "        ),\r\n",
      "        spp_kernal_sizes=(\r\n",
      "            5,\r\n",
      "            9,\r\n",
      "            13,\r\n",
      "        ),\r\n",
      "        type='CSPDarknet',\r\n",
      "        use_depthwise=False,\r\n",
      "        widen_factor=1.25),\r\n",
      "    bbox_head=dict(\r\n",
      "        act_cfg=dict(type='Swish'),\r\n",
      "        feat_channels=320,\r\n",
      "        in_channels=320,\r\n",
      "        loss_bbox=dict(\r\n",
      "            eps=1e-16,\r\n",
      "            loss_weight=5.0,\r\n",
      "            mode='square',\r\n",
      "            reduction='sum',\r\n",
      "            type='IoULoss'),\r\n",
      "        loss_cls=dict(\r\n",
      "            loss_weight=1.0,\r\n",
      "            reduction='sum',\r\n",
      "            type='CrossEntropyLoss',\r\n",
      "            use_sigmoid=True),\r\n",
      "        loss_l1=dict(loss_weight=1.0, reduction='sum', type='L1Loss'),\r\n",
      "        loss_obj=dict(\r\n",
      "            loss_weight=1.0,\r\n",
      "            reduction='sum',\r\n",
      "            type='CrossEntropyLoss',\r\n",
      "            use_sigmoid=True),\r\n",
      "        norm_cfg=dict(eps=0.001, momentum=0.03, type='BN'),\r\n",
      "        num_classes=80,\r\n",
      "        stacked_convs=2,\r\n",
      "        strides=(\r\n",
      "            8,\r\n",
      "            16,\r\n",
      "            32,\r\n",
      "        ),\r\n",
      "        type='YOLOXHead',\r\n",
      "        use_depthwise=False),\r\n",
      "    data_preprocessor=dict(\r\n",
      "        batch_augments=[\r\n",
      "            dict(\r\n",
      "                interval=10,\r\n",
      "                random_size_range=(\r\n",
      "                    480,\r\n",
      "                    800,\r\n",
      "                ),\r\n",
      "                size_divisor=32,\r\n",
      "                type='BatchSyncRandomResize'),\r\n",
      "        ],\r\n",
      "        pad_size_divisor=32,\r\n",
      "        type='DetDataPreprocessor'),\r\n",
      "    neck=dict(\r\n",
      "        act_cfg=dict(type='Swish'),\r\n",
      "        in_channels=[\r\n",
      "            320,\r\n",
      "            640,\r\n",
      "            1280,\r\n",
      "        ],\r\n",
      "        norm_cfg=dict(eps=0.001, momentum=0.03, type='BN'),\r\n",
      "        num_csp_blocks=4,\r\n",
      "        out_channels=320,\r\n",
      "        type='YOLOXPAFPN',\r\n",
      "        upsample_cfg=dict(mode='nearest', scale_factor=2),\r\n",
      "        use_depthwise=False),\r\n",
      "    test_cfg=dict(nms=dict(iou_threshold=0.65, type='nms'), score_thr=0.01),\r\n",
      "    train_cfg=dict(assigner=dict(center_radius=2.5, type='SimOTAAssigner')),\r\n",
      "    type='YOLOX')\r\n",
      "num_last_epochs = 15\r\n",
      "optim_wrapper = dict(\r\n",
      "    optimizer=dict(\r\n",
      "        lr=0.01, momentum=0.9, nesterov=True, type='SGD', weight_decay=0.0005),\r\n",
      "    paramwise_cfg=dict(bias_decay_mult=0.0, norm_decay_mult=0.0),\r\n",
      "    type='OptimWrapper')\r\n",
      "param_scheduler = [\r\n",
      "    dict(\r\n",
      "        begin=0,\r\n",
      "        by_epoch=True,\r\n",
      "        convert_to_iter_based=True,\r\n",
      "        end=5,\r\n",
      "        type='mmdet.QuadraticWarmupLR'),\r\n",
      "    dict(\r\n",
      "        T_max=285,\r\n",
      "        begin=5,\r\n",
      "        by_epoch=True,\r\n",
      "        convert_to_iter_based=True,\r\n",
      "        end=285,\r\n",
      "        eta_min=0.0005,\r\n",
      "        type='CosineAnnealingLR'),\r\n",
      "    dict(begin=285, by_epoch=True, end=300, factor=1, type='ConstantLR'),\r\n",
      "]\r\n",
      "resume = False\r\n",
      "test_cfg = dict(type='TestLoop')\r\n",
      "test_dataloader = dict(\r\n",
      "    batch_size=8,\r\n",
      "    dataset=dict(\r\n",
      "        ann_file='annotations/instances_val2017.json',\r\n",
      "        backend_args=None,\r\n",
      "        data_prefix=dict(img='val2017/'),\r\n",
      "        data_root='data/coco/',\r\n",
      "        pipeline=[\r\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "            dict(keep_ratio=True, scale=(\r\n",
      "                640,\r\n",
      "                640,\r\n",
      "            ), type='Resize'),\r\n",
      "            dict(\r\n",
      "                pad_to_square=True,\r\n",
      "                pad_val=dict(img=(\r\n",
      "                    114.0,\r\n",
      "                    114.0,\r\n",
      "                    114.0,\r\n",
      "                )),\r\n",
      "                type='Pad'),\r\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\r\n",
      "            dict(\r\n",
      "                meta_keys=(\r\n",
      "                    'img_id',\r\n",
      "                    'img_path',\r\n",
      "                    'ori_shape',\r\n",
      "                    'img_shape',\r\n",
      "                    'scale_factor',\r\n",
      "                ),\r\n",
      "                type='PackDetInputs'),\r\n",
      "        ],\r\n",
      "        test_mode=True,\r\n",
      "        type='CocoDataset'),\r\n",
      "    drop_last=False,\r\n",
      "    num_workers=4,\r\n",
      "    persistent_workers=True,\r\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\r\n",
      "test_evaluator = dict(\r\n",
      "    ann_file='data/coco/annotations/instances_val2017.json',\r\n",
      "    backend_args=None,\r\n",
      "    metric='bbox',\r\n",
      "    type='CocoMetric')\r\n",
      "test_pipeline = [\r\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "    dict(keep_ratio=True, scale=(\r\n",
      "        640,\r\n",
      "        640,\r\n",
      "    ), type='Resize'),\r\n",
      "    dict(\r\n",
      "        pad_to_square=True,\r\n",
      "        pad_val=dict(img=(\r\n",
      "            114.0,\r\n",
      "            114.0,\r\n",
      "            114.0,\r\n",
      "        )),\r\n",
      "        type='Pad'),\r\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\r\n",
      "    dict(\r\n",
      "        meta_keys=(\r\n",
      "            'img_id',\r\n",
      "            'img_path',\r\n",
      "            'ori_shape',\r\n",
      "            'img_shape',\r\n",
      "            'scale_factor',\r\n",
      "        ),\r\n",
      "        type='PackDetInputs'),\r\n",
      "]\r\n",
      "train_cfg = dict(max_epochs=300, type='EpochBasedTrainLoop', val_interval=10)\r\n",
      "train_dataloader = dict(\r\n",
      "    batch_size=8,\r\n",
      "    dataset=dict(\r\n",
      "        dataset=dict(\r\n",
      "            ann_file='annotations/instances_train2017.json',\r\n",
      "            backend_args=None,\r\n",
      "            data_prefix=dict(img='train2017/'),\r\n",
      "            data_root='data/coco/',\r\n",
      "            filter_cfg=dict(filter_empty_gt=False, min_size=32),\r\n",
      "            pipeline=[\r\n",
      "                dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "                dict(type='LoadAnnotations', with_bbox=True),\r\n",
      "            ],\r\n",
      "            type='CocoDataset'),\r\n",
      "        pipeline=[\r\n",
      "            dict(img_scale=(\r\n",
      "                640,\r\n",
      "                640,\r\n",
      "            ), pad_val=114.0, type='Mosaic'),\r\n",
      "            dict(\r\n",
      "                border=(\r\n",
      "                    -320,\r\n",
      "                    -320,\r\n",
      "                ),\r\n",
      "                scaling_ratio_range=(\r\n",
      "                    0.1,\r\n",
      "                    2,\r\n",
      "                ),\r\n",
      "                type='RandomAffine'),\r\n",
      "            dict(\r\n",
      "                img_scale=(\r\n",
      "                    640,\r\n",
      "                    640,\r\n",
      "                ),\r\n",
      "                pad_val=114.0,\r\n",
      "                ratio_range=(\r\n",
      "                    0.8,\r\n",
      "                    1.6,\r\n",
      "                ),\r\n",
      "                type='MixUp'),\r\n",
      "            dict(type='YOLOXHSVRandomAug'),\r\n",
      "            dict(prob=0.5, type='RandomFlip'),\r\n",
      "            dict(keep_ratio=True, scale=(\r\n",
      "                640,\r\n",
      "                640,\r\n",
      "            ), type='Resize'),\r\n",
      "            dict(\r\n",
      "                pad_to_square=True,\r\n",
      "                pad_val=dict(img=(\r\n",
      "                    114.0,\r\n",
      "                    114.0,\r\n",
      "                    114.0,\r\n",
      "                )),\r\n",
      "                type='Pad'),\r\n",
      "            dict(\r\n",
      "                keep_empty=False,\r\n",
      "                min_gt_bbox_wh=(\r\n",
      "                    1,\r\n",
      "                    1,\r\n",
      "                ),\r\n",
      "                type='FilterAnnotations'),\r\n",
      "            dict(type='PackDetInputs'),\r\n",
      "        ],\r\n",
      "        type='MultiImageMixDataset'),\r\n",
      "    num_workers=4,\r\n",
      "    persistent_workers=True,\r\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\r\n",
      "train_dataset = dict(\r\n",
      "    dataset=dict(\r\n",
      "        ann_file='annotations/instances_train2017.json',\r\n",
      "        backend_args=None,\r\n",
      "        data_prefix=dict(img='train2017/'),\r\n",
      "        data_root='data/coco/',\r\n",
      "        filter_cfg=dict(filter_empty_gt=False, min_size=32),\r\n",
      "        pipeline=[\r\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\r\n",
      "        ],\r\n",
      "        type='CocoDataset'),\r\n",
      "    pipeline=[\r\n",
      "        dict(img_scale=(\r\n",
      "            640,\r\n",
      "            640,\r\n",
      "        ), pad_val=114.0, type='Mosaic'),\r\n",
      "        dict(\r\n",
      "            border=(\r\n",
      "                -320,\r\n",
      "                -320,\r\n",
      "            ),\r\n",
      "            scaling_ratio_range=(\r\n",
      "                0.1,\r\n",
      "                2,\r\n",
      "            ),\r\n",
      "            type='RandomAffine'),\r\n",
      "        dict(\r\n",
      "            img_scale=(\r\n",
      "                640,\r\n",
      "                640,\r\n",
      "            ),\r\n",
      "            pad_val=114.0,\r\n",
      "            ratio_range=(\r\n",
      "                0.8,\r\n",
      "                1.6,\r\n",
      "            ),\r\n",
      "            type='MixUp'),\r\n",
      "        dict(type='YOLOXHSVRandomAug'),\r\n",
      "        dict(prob=0.5, type='RandomFlip'),\r\n",
      "        dict(keep_ratio=True, scale=(\r\n",
      "            640,\r\n",
      "            640,\r\n",
      "        ), type='Resize'),\r\n",
      "        dict(\r\n",
      "            pad_to_square=True,\r\n",
      "            pad_val=dict(img=(\r\n",
      "                114.0,\r\n",
      "                114.0,\r\n",
      "                114.0,\r\n",
      "            )),\r\n",
      "            type='Pad'),\r\n",
      "        dict(\r\n",
      "            keep_empty=False,\r\n",
      "            min_gt_bbox_wh=(\r\n",
      "                1,\r\n",
      "                1,\r\n",
      "            ),\r\n",
      "            type='FilterAnnotations'),\r\n",
      "        dict(type='PackDetInputs'),\r\n",
      "    ],\r\n",
      "    type='MultiImageMixDataset')\r\n",
      "train_pipeline = [\r\n",
      "    dict(img_scale=(\r\n",
      "        640,\r\n",
      "        640,\r\n",
      "    ), pad_val=114.0, type='Mosaic'),\r\n",
      "    dict(\r\n",
      "        border=(\r\n",
      "            -320,\r\n",
      "            -320,\r\n",
      "        ),\r\n",
      "        scaling_ratio_range=(\r\n",
      "            0.1,\r\n",
      "            2,\r\n",
      "        ),\r\n",
      "        type='RandomAffine'),\r\n",
      "    dict(\r\n",
      "        img_scale=(\r\n",
      "            640,\r\n",
      "            640,\r\n",
      "        ),\r\n",
      "        pad_val=114.0,\r\n",
      "        ratio_range=(\r\n",
      "            0.8,\r\n",
      "            1.6,\r\n",
      "        ),\r\n",
      "        type='MixUp'),\r\n",
      "    dict(type='YOLOXHSVRandomAug'),\r\n",
      "    dict(prob=0.5, type='RandomFlip'),\r\n",
      "    dict(keep_ratio=True, scale=(\r\n",
      "        640,\r\n",
      "        640,\r\n",
      "    ), type='Resize'),\r\n",
      "    dict(\r\n",
      "        pad_to_square=True,\r\n",
      "        pad_val=dict(img=(\r\n",
      "            114.0,\r\n",
      "            114.0,\r\n",
      "            114.0,\r\n",
      "        )),\r\n",
      "        type='Pad'),\r\n",
      "    dict(keep_empty=False, min_gt_bbox_wh=(\r\n",
      "        1,\r\n",
      "        1,\r\n",
      "    ), type='FilterAnnotations'),\r\n",
      "    dict(type='PackDetInputs'),\r\n",
      "]\r\n",
      "tta_model = dict(\r\n",
      "    tta_cfg=dict(max_per_img=100, nms=dict(iou_threshold=0.65, type='nms')),\r\n",
      "    type='DetTTAModel')\r\n",
      "tta_pipeline = [\r\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "    dict(\r\n",
      "        transforms=[\r\n",
      "            [\r\n",
      "                dict(keep_ratio=True, scale=(\r\n",
      "                    640,\r\n",
      "                    640,\r\n",
      "                ), type='Resize'),\r\n",
      "                dict(keep_ratio=True, scale=(\r\n",
      "                    320,\r\n",
      "                    320,\r\n",
      "                ), type='Resize'),\r\n",
      "                dict(keep_ratio=True, scale=(\r\n",
      "                    960,\r\n",
      "                    960,\r\n",
      "                ), type='Resize'),\r\n",
      "            ],\r\n",
      "            [\r\n",
      "                dict(prob=1.0, type='RandomFlip'),\r\n",
      "                dict(prob=0.0, type='RandomFlip'),\r\n",
      "            ],\r\n",
      "            [\r\n",
      "                dict(\r\n",
      "                    pad_to_square=True,\r\n",
      "                    pad_val=dict(img=(\r\n",
      "                        114.0,\r\n",
      "                        114.0,\r\n",
      "                        114.0,\r\n",
      "                    )),\r\n",
      "                    type='Pad'),\r\n",
      "            ],\r\n",
      "            [\r\n",
      "                dict(type='LoadAnnotations', with_bbox=True),\r\n",
      "            ],\r\n",
      "            [\r\n",
      "                dict(\r\n",
      "                    meta_keys=(\r\n",
      "                        'img_id',\r\n",
      "                        'img_path',\r\n",
      "                        'ori_shape',\r\n",
      "                        'img_shape',\r\n",
      "                        'scale_factor',\r\n",
      "                        'flip',\r\n",
      "                        'flip_direction',\r\n",
      "                    ),\r\n",
      "                    type='PackDetInputs'),\r\n",
      "            ],\r\n",
      "        ],\r\n",
      "        type='TestTimeAug'),\r\n",
      "]\r\n",
      "val_cfg = dict(type='ValLoop')\r\n",
      "val_dataloader = dict(\r\n",
      "    batch_size=8,\r\n",
      "    dataset=dict(\r\n",
      "        ann_file='annotations/instances_val2017.json',\r\n",
      "        backend_args=None,\r\n",
      "        data_prefix=dict(img='val2017/'),\r\n",
      "        data_root='data/coco/',\r\n",
      "        pipeline=[\r\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "            dict(keep_ratio=True, scale=(\r\n",
      "                640,\r\n",
      "                640,\r\n",
      "            ), type='Resize'),\r\n",
      "            dict(\r\n",
      "                pad_to_square=True,\r\n",
      "                pad_val=dict(img=(\r\n",
      "                    114.0,\r\n",
      "                    114.0,\r\n",
      "                    114.0,\r\n",
      "                )),\r\n",
      "                type='Pad'),\r\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\r\n",
      "            dict(\r\n",
      "                meta_keys=(\r\n",
      "                    'img_id',\r\n",
      "                    'img_path',\r\n",
      "                    'ori_shape',\r\n",
      "                    'img_shape',\r\n",
      "                    'scale_factor',\r\n",
      "                ),\r\n",
      "                type='PackDetInputs'),\r\n",
      "        ],\r\n",
      "        test_mode=True,\r\n",
      "        type='CocoDataset'),\r\n",
      "    drop_last=False,\r\n",
      "    num_workers=4,\r\n",
      "    persistent_workers=True,\r\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\r\n",
      "val_evaluator = dict(\r\n",
      "    ann_file='data/coco/annotations/instances_val2017.json',\r\n",
      "    backend_args=None,\r\n",
      "    metric='bbox',\r\n",
      "    type='CocoMetric')\r\n",
      "vis_backends = [\r\n",
      "    dict(type='LocalVisBackend'),\r\n",
      "]\r\n",
      "visualizer = dict(\r\n",
      "    name='visualizer',\r\n",
      "    type='DetLocalVisualizer',\r\n",
      "    vis_backends=[\r\n",
      "        dict(type='LocalVisBackend'),\r\n",
      "    ])\r\n",
      "work_dir = './work_dirs/yolox_x_8xb8-300e_coco'\r\n",
      "\r\n",
      "05/10 23:52:01 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\r\n",
      "05/10 23:52:01 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Hooks will be executed in the following order:\r\n",
      "before_run:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(49          ) EMAHook                            \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "after_load_checkpoint:\r\n",
      "(49          ) EMAHook                            \r\n",
      " -------------------- \r\n",
      "before_train:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(49          ) EMAHook                            \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "before_train_epoch:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(48          ) YOLOXModeSwitchHook                \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(NORMAL      ) DistSamplerSeedHook                \r\n",
      " -------------------- \r\n",
      "before_train_iter:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_train_iter:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(49          ) EMAHook                            \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      "(LOW         ) ParamSchedulerHook                 \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "after_train_epoch:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(LOW         ) ParamSchedulerHook                 \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "before_val:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "before_val_epoch:\r\n",
      "(48          ) SyncNormHook                       \r\n",
      "(49          ) EMAHook                            \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "before_val_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_val_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(NORMAL      ) DetVisualizationHook               \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "after_val_epoch:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(49          ) EMAHook                            \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      "(LOW         ) ParamSchedulerHook                 \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "after_val:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "before_save_checkpoint:\r\n",
      "(49          ) EMAHook                            \r\n",
      " -------------------- \r\n",
      "after_train:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "before_test:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "before_test_epoch:\r\n",
      "(49          ) EMAHook                            \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "before_test_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_test_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(NORMAL      ) DetVisualizationHook               \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "after_test_epoch:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(49          ) EMAHook                            \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "after_test:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "after_run:\r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "loading annotations into memory...\r\n",
      "Done (t=0.57s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "loading annotations into memory...\r\n",
      "Done (t=0.41s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "Loads checkpoint by local backend from path: checkpoints/yolox_x.pth\r\n",
      "05/10 23:52:04 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Load checkpoint from checkpoints/yolox_x.pth\r\n",
      "/mnt/ntfs/SSD1/_Master6/RM/mmdetection/.venv/lib64/python3.11/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\r\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\r\n",
      "05/10 23:52:18 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 50/625]    eta: 0:02:40  time: 0.2783  data_time: 0.0121  memory: 1812  \r\n",
      "05/10 23:52:31 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [100/625]    eta: 0:02:22  time: 0.2659  data_time: 0.0084  memory: 1812  \r\n",
      "05/10 23:52:44 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [150/625]    eta: 0:02:08  time: 0.2657  data_time: 0.0081  memory: 1812  \r\n",
      "05/10 23:52:58 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [200/625]    eta: 0:01:54  time: 0.2662  data_time: 0.0082  memory: 1812  \r\n",
      "05/10 23:53:12 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [250/625]    eta: 0:01:41  time: 0.2824  data_time: 0.0090  memory: 1812  \r\n",
      "05/10 23:53:26 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [300/625]    eta: 0:01:28  time: 0.2798  data_time: 0.0083  memory: 1812  \r\n",
      "05/10 23:53:39 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [350/625]    eta: 0:01:15  time: 0.2756  data_time: 0.0087  memory: 1812  \r\n",
      "05/10 23:53:53 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [400/625]    eta: 0:01:01  time: 0.2684  data_time: 0.0091  memory: 1812  \r\n",
      "05/10 23:54:06 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [450/625]    eta: 0:00:47  time: 0.2680  data_time: 0.0083  memory: 1812  \r\n",
      "05/10 23:54:20 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [500/625]    eta: 0:00:33  time: 0.2654  data_time: 0.0084  memory: 1812  \r\n",
      "05/10 23:54:33 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [550/625]    eta: 0:00:20  time: 0.2624  data_time: 0.0082  memory: 1812  \r\n",
      "05/10 23:54:46 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [600/625]    eta: 0:00:06  time: 0.2673  data_time: 0.0089  memory: 1812  \r\n",
      "05/10 23:54:54 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Evaluating bbox...\r\n",
      "Loading and preparing results...\r\n",
      "DONE (t=0.57s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "Running per image evaluation...\r\n",
      "Evaluate annotation type *bbox*\r\n",
      "DONE (t=18.71s).\r\n",
      "Accumulating evaluation results...\r\n",
      "DONE (t=2.85s).\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.506\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.684\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.550\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.320\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.556\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.667\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.636\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.636\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.636\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.433\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.684\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.792\r\n",
      "05/10 23:55:17 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - bbox_mAP_copypaste: 0.506 0.684 0.550 0.320 0.556 0.667\r\n",
      "05/10 23:55:18 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [625/625]    coco/bbox_mAP: 0.5060  coco/bbox_mAP_50: 0.6840  coco/bbox_mAP_75: 0.5500  coco/bbox_mAP_s: 0.3200  coco/bbox_mAP_m: 0.5560  coco/bbox_mAP_l: 0.6670  data_time: 0.0088  time: 0.2701\r\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Visualize Prediction as Image",
   "id": "ffe76532c7075136"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/10 22:34:10 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - \r\n",
      "------------------------------------------------------------\r\n",
      "System environment:\r\n",
      "    sys.platform: linux\r\n",
      "    Python: 3.11.9 (main, Apr 17 2024, 00:00:00) [GCC 13.2.1 20240316 (Red Hat 13.2.1-7)]\r\n",
      "    CUDA available: True\r\n",
      "    MUSA available: False\r\n",
      "    numpy_random_seed: 1655412138\r\n",
      "    GPU 0: NVIDIA GeForce RTX 3070\r\n",
      "    CUDA_HOME: /usr/local/cuda\r\n",
      "    NVCC: Cuda compilation tools, release 12.4, V12.4.131\r\n",
      "    GCC: gcc (GCC) 13.2.1 20240316 (Red Hat 13.2.1-7)\r\n",
      "    PyTorch: 2.1.0+cu121\r\n",
      "    PyTorch compiling details: PyTorch built with:\r\n",
      "  - GCC 9.3\r\n",
      "  - C++ Version: 201703\r\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\r\n",
      "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\r\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\r\n",
      "  - LAPACK is enabled (usually provided by MKL)\r\n",
      "  - NNPACK is enabled\r\n",
      "  - CPU capability usage: AVX2\r\n",
      "  - CUDA Runtime 12.1\r\n",
      "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\r\n",
      "  - CuDNN 8.9.2\r\n",
      "  - Magma 2.6.1\r\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \r\n",
      "\r\n",
      "    TorchVision: 0.16.0+cu121\r\n",
      "    OpenCV: 4.9.0\r\n",
      "    MMEngine: 0.10.4\r\n",
      "\r\n",
      "Runtime environment:\r\n",
      "    cudnn_benchmark: False\r\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\r\n",
      "    dist_cfg: {'backend': 'nccl'}\r\n",
      "    seed: 1655412138\r\n",
      "    Distributed launcher: none\r\n",
      "    Distributed training: False\r\n",
      "    GPU number: 1\r\n",
      "------------------------------------------------------------\r\n",
      "\r\n",
      "05/10 22:34:10 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Config:\r\n",
      "auto_scale_lr = dict(base_batch_size=64, enable=False)\r\n",
      "backend_args = None\r\n",
      "base_lr = 0.01\r\n",
      "custom_hooks = [\r\n",
      "    dict(num_last_epochs=15, priority=48, type='YOLOXModeSwitchHook'),\r\n",
      "    dict(priority=48, type='SyncNormHook'),\r\n",
      "    dict(\r\n",
      "        ema_type='ExpMomentumEMA',\r\n",
      "        momentum=0.0001,\r\n",
      "        priority=49,\r\n",
      "        type='EMAHook',\r\n",
      "        update_buffers=True),\r\n",
      "]\r\n",
      "data_root = 'data/coco/'\r\n",
      "dataset_type = 'CocoDataset'\r\n",
      "default_hooks = dict(\r\n",
      "    checkpoint=dict(interval=10, max_keep_ckpts=3, type='CheckpointHook'),\r\n",
      "    logger=dict(interval=50, type='LoggerHook'),\r\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\r\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\r\n",
      "    timer=dict(type='IterTimerHook'),\r\n",
      "    visualization=dict(type='DetVisualizationHook'))\r\n",
      "default_scope = 'mmdet'\r\n",
      "env_cfg = dict(\r\n",
      "    cudnn_benchmark=False,\r\n",
      "    dist_cfg=dict(backend='nccl'),\r\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\r\n",
      "img_scale = (\r\n",
      "    640,\r\n",
      "    640,\r\n",
      ")\r\n",
      "img_scales = [\r\n",
      "    (\r\n",
      "        640,\r\n",
      "        640,\r\n",
      "    ),\r\n",
      "    (\r\n",
      "        320,\r\n",
      "        320,\r\n",
      "    ),\r\n",
      "    (\r\n",
      "        960,\r\n",
      "        960,\r\n",
      "    ),\r\n",
      "]\r\n",
      "interval = 10\r\n",
      "launcher = 'none'\r\n",
      "load_from = 'checkpoints/yolox_s.pth'\r\n",
      "log_level = 'INFO'\r\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\r\n",
      "max_epochs = 300\r\n",
      "model = dict(\r\n",
      "    backbone=dict(\r\n",
      "        act_cfg=dict(type='Swish'),\r\n",
      "        deepen_factor=0.33,\r\n",
      "        norm_cfg=dict(eps=0.001, momentum=0.03, type='BN'),\r\n",
      "        out_indices=(\r\n",
      "            2,\r\n",
      "            3,\r\n",
      "            4,\r\n",
      "        ),\r\n",
      "        spp_kernal_sizes=(\r\n",
      "            5,\r\n",
      "            9,\r\n",
      "            13,\r\n",
      "        ),\r\n",
      "        type='CSPDarknet',\r\n",
      "        use_depthwise=False,\r\n",
      "        widen_factor=0.5),\r\n",
      "    bbox_head=dict(\r\n",
      "        act_cfg=dict(type='Swish'),\r\n",
      "        feat_channels=128,\r\n",
      "        in_channels=128,\r\n",
      "        loss_bbox=dict(\r\n",
      "            eps=1e-16,\r\n",
      "            loss_weight=5.0,\r\n",
      "            mode='square',\r\n",
      "            reduction='sum',\r\n",
      "            type='IoULoss'),\r\n",
      "        loss_cls=dict(\r\n",
      "            loss_weight=1.0,\r\n",
      "            reduction='sum',\r\n",
      "            type='CrossEntropyLoss',\r\n",
      "            use_sigmoid=True),\r\n",
      "        loss_l1=dict(loss_weight=1.0, reduction='sum', type='L1Loss'),\r\n",
      "        loss_obj=dict(\r\n",
      "            loss_weight=1.0,\r\n",
      "            reduction='sum',\r\n",
      "            type='CrossEntropyLoss',\r\n",
      "            use_sigmoid=True),\r\n",
      "        norm_cfg=dict(eps=0.001, momentum=0.03, type='BN'),\r\n",
      "        num_classes=80,\r\n",
      "        stacked_convs=2,\r\n",
      "        strides=(\r\n",
      "            8,\r\n",
      "            16,\r\n",
      "            32,\r\n",
      "        ),\r\n",
      "        type='YOLOXHead',\r\n",
      "        use_depthwise=False),\r\n",
      "    data_preprocessor=dict(\r\n",
      "        batch_augments=[\r\n",
      "            dict(\r\n",
      "                interval=10,\r\n",
      "                random_size_range=(\r\n",
      "                    480,\r\n",
      "                    800,\r\n",
      "                ),\r\n",
      "                size_divisor=32,\r\n",
      "                type='BatchSyncRandomResize'),\r\n",
      "        ],\r\n",
      "        pad_size_divisor=32,\r\n",
      "        type='DetDataPreprocessor'),\r\n",
      "    neck=dict(\r\n",
      "        act_cfg=dict(type='Swish'),\r\n",
      "        in_channels=[\r\n",
      "            128,\r\n",
      "            256,\r\n",
      "            512,\r\n",
      "        ],\r\n",
      "        norm_cfg=dict(eps=0.001, momentum=0.03, type='BN'),\r\n",
      "        num_csp_blocks=1,\r\n",
      "        out_channels=128,\r\n",
      "        type='YOLOXPAFPN',\r\n",
      "        upsample_cfg=dict(mode='nearest', scale_factor=2),\r\n",
      "        use_depthwise=False),\r\n",
      "    test_cfg=dict(nms=dict(iou_threshold=0.65, type='nms'), score_thr=0.01),\r\n",
      "    train_cfg=dict(assigner=dict(center_radius=2.5, type='SimOTAAssigner')),\r\n",
      "    type='YOLOX')\r\n",
      "num_last_epochs = 15\r\n",
      "optim_wrapper = dict(\r\n",
      "    optimizer=dict(\r\n",
      "        lr=0.01, momentum=0.9, nesterov=True, type='SGD', weight_decay=0.0005),\r\n",
      "    paramwise_cfg=dict(bias_decay_mult=0.0, norm_decay_mult=0.0),\r\n",
      "    type='OptimWrapper')\r\n",
      "param_scheduler = [\r\n",
      "    dict(\r\n",
      "        begin=0,\r\n",
      "        by_epoch=True,\r\n",
      "        convert_to_iter_based=True,\r\n",
      "        end=5,\r\n",
      "        type='mmdet.QuadraticWarmupLR'),\r\n",
      "    dict(\r\n",
      "        T_max=285,\r\n",
      "        begin=5,\r\n",
      "        by_epoch=True,\r\n",
      "        convert_to_iter_based=True,\r\n",
      "        end=285,\r\n",
      "        eta_min=0.0005,\r\n",
      "        type='CosineAnnealingLR'),\r\n",
      "    dict(begin=285, by_epoch=True, end=300, factor=1, type='ConstantLR'),\r\n",
      "]\r\n",
      "resume = False\r\n",
      "test_cfg = dict(type='TestLoop')\r\n",
      "test_dataloader = dict(\r\n",
      "    batch_size=8,\r\n",
      "    dataset=dict(\r\n",
      "        ann_file='annotations/instances_val2017.json',\r\n",
      "        backend_args=None,\r\n",
      "        data_prefix=dict(img='val2017/'),\r\n",
      "        data_root='data/coco/',\r\n",
      "        pipeline=[\r\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "            dict(keep_ratio=True, scale=(\r\n",
      "                640,\r\n",
      "                640,\r\n",
      "            ), type='Resize'),\r\n",
      "            dict(\r\n",
      "                pad_to_square=True,\r\n",
      "                pad_val=dict(img=(\r\n",
      "                    114.0,\r\n",
      "                    114.0,\r\n",
      "                    114.0,\r\n",
      "                )),\r\n",
      "                type='Pad'),\r\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\r\n",
      "            dict(\r\n",
      "                meta_keys=(\r\n",
      "                    'img_id',\r\n",
      "                    'img_path',\r\n",
      "                    'ori_shape',\r\n",
      "                    'img_shape',\r\n",
      "                    'scale_factor',\r\n",
      "                ),\r\n",
      "                type='PackDetInputs'),\r\n",
      "        ],\r\n",
      "        test_mode=True,\r\n",
      "        type='CocoDataset'),\r\n",
      "    drop_last=False,\r\n",
      "    num_workers=4,\r\n",
      "    persistent_workers=True,\r\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\r\n",
      "test_evaluator = dict(\r\n",
      "    ann_file='data/coco/annotations/instances_val2017.json',\r\n",
      "    backend_args=None,\r\n",
      "    metric='bbox',\r\n",
      "    type='CocoMetric')\r\n",
      "test_pipeline = [\r\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "    dict(keep_ratio=True, scale=(\r\n",
      "        640,\r\n",
      "        640,\r\n",
      "    ), type='Resize'),\r\n",
      "    dict(\r\n",
      "        pad_to_square=True,\r\n",
      "        pad_val=dict(img=(\r\n",
      "            114.0,\r\n",
      "            114.0,\r\n",
      "            114.0,\r\n",
      "        )),\r\n",
      "        type='Pad'),\r\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\r\n",
      "    dict(\r\n",
      "        meta_keys=(\r\n",
      "            'img_id',\r\n",
      "            'img_path',\r\n",
      "            'ori_shape',\r\n",
      "            'img_shape',\r\n",
      "            'scale_factor',\r\n",
      "        ),\r\n",
      "        type='PackDetInputs'),\r\n",
      "]\r\n",
      "train_cfg = dict(max_epochs=300, type='EpochBasedTrainLoop', val_interval=10)\r\n",
      "train_dataloader = dict(\r\n",
      "    batch_size=8,\r\n",
      "    dataset=dict(\r\n",
      "        dataset=dict(\r\n",
      "            ann_file='annotations/instances_train2017.json',\r\n",
      "            backend_args=None,\r\n",
      "            data_prefix=dict(img='train2017/'),\r\n",
      "            data_root='data/coco/',\r\n",
      "            filter_cfg=dict(filter_empty_gt=False, min_size=32),\r\n",
      "            pipeline=[\r\n",
      "                dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "                dict(type='LoadAnnotations', with_bbox=True),\r\n",
      "            ],\r\n",
      "            type='CocoDataset'),\r\n",
      "        pipeline=[\r\n",
      "            dict(img_scale=(\r\n",
      "                640,\r\n",
      "                640,\r\n",
      "            ), pad_val=114.0, type='Mosaic'),\r\n",
      "            dict(\r\n",
      "                border=(\r\n",
      "                    -320,\r\n",
      "                    -320,\r\n",
      "                ),\r\n",
      "                scaling_ratio_range=(\r\n",
      "                    0.1,\r\n",
      "                    2,\r\n",
      "                ),\r\n",
      "                type='RandomAffine'),\r\n",
      "            dict(\r\n",
      "                img_scale=(\r\n",
      "                    640,\r\n",
      "                    640,\r\n",
      "                ),\r\n",
      "                pad_val=114.0,\r\n",
      "                ratio_range=(\r\n",
      "                    0.8,\r\n",
      "                    1.6,\r\n",
      "                ),\r\n",
      "                type='MixUp'),\r\n",
      "            dict(type='YOLOXHSVRandomAug'),\r\n",
      "            dict(prob=0.5, type='RandomFlip'),\r\n",
      "            dict(keep_ratio=True, scale=(\r\n",
      "                640,\r\n",
      "                640,\r\n",
      "            ), type='Resize'),\r\n",
      "            dict(\r\n",
      "                pad_to_square=True,\r\n",
      "                pad_val=dict(img=(\r\n",
      "                    114.0,\r\n",
      "                    114.0,\r\n",
      "                    114.0,\r\n",
      "                )),\r\n",
      "                type='Pad'),\r\n",
      "            dict(\r\n",
      "                keep_empty=False,\r\n",
      "                min_gt_bbox_wh=(\r\n",
      "                    1,\r\n",
      "                    1,\r\n",
      "                ),\r\n",
      "                type='FilterAnnotations'),\r\n",
      "            dict(type='PackDetInputs'),\r\n",
      "        ],\r\n",
      "        type='MultiImageMixDataset'),\r\n",
      "    num_workers=4,\r\n",
      "    persistent_workers=True,\r\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\r\n",
      "train_dataset = dict(\r\n",
      "    dataset=dict(\r\n",
      "        ann_file='annotations/instances_train2017.json',\r\n",
      "        backend_args=None,\r\n",
      "        data_prefix=dict(img='train2017/'),\r\n",
      "        data_root='data/coco/',\r\n",
      "        filter_cfg=dict(filter_empty_gt=False, min_size=32),\r\n",
      "        pipeline=[\r\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\r\n",
      "        ],\r\n",
      "        type='CocoDataset'),\r\n",
      "    pipeline=[\r\n",
      "        dict(img_scale=(\r\n",
      "            640,\r\n",
      "            640,\r\n",
      "        ), pad_val=114.0, type='Mosaic'),\r\n",
      "        dict(\r\n",
      "            border=(\r\n",
      "                -320,\r\n",
      "                -320,\r\n",
      "            ),\r\n",
      "            scaling_ratio_range=(\r\n",
      "                0.1,\r\n",
      "                2,\r\n",
      "            ),\r\n",
      "            type='RandomAffine'),\r\n",
      "        dict(\r\n",
      "            img_scale=(\r\n",
      "                640,\r\n",
      "                640,\r\n",
      "            ),\r\n",
      "            pad_val=114.0,\r\n",
      "            ratio_range=(\r\n",
      "                0.8,\r\n",
      "                1.6,\r\n",
      "            ),\r\n",
      "            type='MixUp'),\r\n",
      "        dict(type='YOLOXHSVRandomAug'),\r\n",
      "        dict(prob=0.5, type='RandomFlip'),\r\n",
      "        dict(keep_ratio=True, scale=(\r\n",
      "            640,\r\n",
      "            640,\r\n",
      "        ), type='Resize'),\r\n",
      "        dict(\r\n",
      "            pad_to_square=True,\r\n",
      "            pad_val=dict(img=(\r\n",
      "                114.0,\r\n",
      "                114.0,\r\n",
      "                114.0,\r\n",
      "            )),\r\n",
      "            type='Pad'),\r\n",
      "        dict(\r\n",
      "            keep_empty=False,\r\n",
      "            min_gt_bbox_wh=(\r\n",
      "                1,\r\n",
      "                1,\r\n",
      "            ),\r\n",
      "            type='FilterAnnotations'),\r\n",
      "        dict(type='PackDetInputs'),\r\n",
      "    ],\r\n",
      "    type='MultiImageMixDataset')\r\n",
      "train_pipeline = [\r\n",
      "    dict(img_scale=(\r\n",
      "        640,\r\n",
      "        640,\r\n",
      "    ), pad_val=114.0, type='Mosaic'),\r\n",
      "    dict(\r\n",
      "        border=(\r\n",
      "            -320,\r\n",
      "            -320,\r\n",
      "        ),\r\n",
      "        scaling_ratio_range=(\r\n",
      "            0.1,\r\n",
      "            2,\r\n",
      "        ),\r\n",
      "        type='RandomAffine'),\r\n",
      "    dict(\r\n",
      "        img_scale=(\r\n",
      "            640,\r\n",
      "            640,\r\n",
      "        ),\r\n",
      "        pad_val=114.0,\r\n",
      "        ratio_range=(\r\n",
      "            0.8,\r\n",
      "            1.6,\r\n",
      "        ),\r\n",
      "        type='MixUp'),\r\n",
      "    dict(type='YOLOXHSVRandomAug'),\r\n",
      "    dict(prob=0.5, type='RandomFlip'),\r\n",
      "    dict(keep_ratio=True, scale=(\r\n",
      "        640,\r\n",
      "        640,\r\n",
      "    ), type='Resize'),\r\n",
      "    dict(\r\n",
      "        pad_to_square=True,\r\n",
      "        pad_val=dict(img=(\r\n",
      "            114.0,\r\n",
      "            114.0,\r\n",
      "            114.0,\r\n",
      "        )),\r\n",
      "        type='Pad'),\r\n",
      "    dict(keep_empty=False, min_gt_bbox_wh=(\r\n",
      "        1,\r\n",
      "        1,\r\n",
      "    ), type='FilterAnnotations'),\r\n",
      "    dict(type='PackDetInputs'),\r\n",
      "]\r\n",
      "tta_model = dict(\r\n",
      "    tta_cfg=dict(max_per_img=100, nms=dict(iou_threshold=0.65, type='nms')),\r\n",
      "    type='DetTTAModel')\r\n",
      "tta_pipeline = [\r\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "    dict(\r\n",
      "        transforms=[\r\n",
      "            [\r\n",
      "                dict(keep_ratio=True, scale=(\r\n",
      "                    640,\r\n",
      "                    640,\r\n",
      "                ), type='Resize'),\r\n",
      "                dict(keep_ratio=True, scale=(\r\n",
      "                    320,\r\n",
      "                    320,\r\n",
      "                ), type='Resize'),\r\n",
      "                dict(keep_ratio=True, scale=(\r\n",
      "                    960,\r\n",
      "                    960,\r\n",
      "                ), type='Resize'),\r\n",
      "            ],\r\n",
      "            [\r\n",
      "                dict(prob=1.0, type='RandomFlip'),\r\n",
      "                dict(prob=0.0, type='RandomFlip'),\r\n",
      "            ],\r\n",
      "            [\r\n",
      "                dict(\r\n",
      "                    pad_to_square=True,\r\n",
      "                    pad_val=dict(img=(\r\n",
      "                        114.0,\r\n",
      "                        114.0,\r\n",
      "                        114.0,\r\n",
      "                    )),\r\n",
      "                    type='Pad'),\r\n",
      "            ],\r\n",
      "            [\r\n",
      "                dict(type='LoadAnnotations', with_bbox=True),\r\n",
      "            ],\r\n",
      "            [\r\n",
      "                dict(\r\n",
      "                    meta_keys=(\r\n",
      "                        'img_id',\r\n",
      "                        'img_path',\r\n",
      "                        'ori_shape',\r\n",
      "                        'img_shape',\r\n",
      "                        'scale_factor',\r\n",
      "                        'flip',\r\n",
      "                        'flip_direction',\r\n",
      "                    ),\r\n",
      "                    type='PackDetInputs'),\r\n",
      "            ],\r\n",
      "        ],\r\n",
      "        type='TestTimeAug'),\r\n",
      "]\r\n",
      "val_cfg = dict(type='ValLoop')\r\n",
      "val_dataloader = dict(\r\n",
      "    batch_size=8,\r\n",
      "    dataset=dict(\r\n",
      "        ann_file='annotations/instances_val2017.json',\r\n",
      "        backend_args=None,\r\n",
      "        data_prefix=dict(img='val2017/'),\r\n",
      "        data_root='data/coco/',\r\n",
      "        pipeline=[\r\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\r\n",
      "            dict(keep_ratio=True, scale=(\r\n",
      "                640,\r\n",
      "                640,\r\n",
      "            ), type='Resize'),\r\n",
      "            dict(\r\n",
      "                pad_to_square=True,\r\n",
      "                pad_val=dict(img=(\r\n",
      "                    114.0,\r\n",
      "                    114.0,\r\n",
      "                    114.0,\r\n",
      "                )),\r\n",
      "                type='Pad'),\r\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\r\n",
      "            dict(\r\n",
      "                meta_keys=(\r\n",
      "                    'img_id',\r\n",
      "                    'img_path',\r\n",
      "                    'ori_shape',\r\n",
      "                    'img_shape',\r\n",
      "                    'scale_factor',\r\n",
      "                ),\r\n",
      "                type='PackDetInputs'),\r\n",
      "        ],\r\n",
      "        test_mode=True,\r\n",
      "        type='CocoDataset'),\r\n",
      "    drop_last=False,\r\n",
      "    num_workers=4,\r\n",
      "    persistent_workers=True,\r\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\r\n",
      "val_evaluator = dict(\r\n",
      "    ann_file='data/coco/annotations/instances_val2017.json',\r\n",
      "    backend_args=None,\r\n",
      "    metric='bbox',\r\n",
      "    type='CocoMetric')\r\n",
      "vis_backends = [\r\n",
      "    dict(type='LocalVisBackend'),\r\n",
      "]\r\n",
      "visualizer = dict(\r\n",
      "    name='visualizer',\r\n",
      "    type='DetLocalVisualizer',\r\n",
      "    vis_backends=[\r\n",
      "        dict(type='LocalVisBackend'),\r\n",
      "    ])\r\n",
      "work_dir = './work_dirs/yolox_s_8xb8-300e_coco'\r\n",
      "\r\n",
      "05/10 22:34:11 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\r\n",
      "05/10 22:34:11 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Hooks will be executed in the following order:\r\n",
      "before_run:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(49          ) EMAHook                            \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "after_load_checkpoint:\r\n",
      "(49          ) EMAHook                            \r\n",
      " -------------------- \r\n",
      "before_train:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(49          ) EMAHook                            \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "before_train_epoch:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(48          ) YOLOXModeSwitchHook                \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(NORMAL      ) DistSamplerSeedHook                \r\n",
      " -------------------- \r\n",
      "before_train_iter:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_train_iter:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(49          ) EMAHook                            \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      "(LOW         ) ParamSchedulerHook                 \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "after_train_epoch:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(LOW         ) ParamSchedulerHook                 \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "before_val:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "before_val_epoch:\r\n",
      "(48          ) SyncNormHook                       \r\n",
      "(49          ) EMAHook                            \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "before_val_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_val_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(NORMAL      ) DetVisualizationHook               \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "after_val_epoch:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(49          ) EMAHook                            \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      "(LOW         ) ParamSchedulerHook                 \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "after_val:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "before_save_checkpoint:\r\n",
      "(49          ) EMAHook                            \r\n",
      " -------------------- \r\n",
      "after_train:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(VERY_LOW    ) CheckpointHook                     \r\n",
      " -------------------- \r\n",
      "before_test:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "before_test_epoch:\r\n",
      "(49          ) EMAHook                            \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "before_test_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      " -------------------- \r\n",
      "after_test_iter:\r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(NORMAL      ) DetVisualizationHook               \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "after_test_epoch:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      "(49          ) EMAHook                            \r\n",
      "(NORMAL      ) IterTimerHook                      \r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "after_test:\r\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \r\n",
      " -------------------- \r\n",
      "after_run:\r\n",
      "(BELOW_NORMAL) LoggerHook                         \r\n",
      " -------------------- \r\n",
      "loading annotations into memory...\r\n",
      "Done (t=0.58s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "loading annotations into memory...\r\n",
      "Done (t=0.42s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "Loads checkpoint by local backend from path: checkpoints/yolox_s.pth\r\n",
      "05/10 22:34:14 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Load checkpoint from checkpoints/yolox_s.pth\r\n",
      "/mnt/ntfs/SSD1/_Master6/RM/mmdetection/.venv/lib64/python3.11/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\r\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\r\n",
      "05/10 22:34:17 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [ 50/625]    eta: 0:00:40  time: 0.0713  data_time: 0.0120  memory: 506  \r\n",
      "05/10 22:34:20 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [100/625]    eta: 0:00:34  time: 0.0602  data_time: 0.0085  memory: 506  \r\n",
      "05/10 22:34:23 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [150/625]    eta: 0:00:30  time: 0.0606  data_time: 0.0085  memory: 506  \r\n",
      "05/10 22:34:26 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [200/625]    eta: 0:00:26  time: 0.0616  data_time: 0.0091  memory: 506  \r\n",
      "05/10 22:34:29 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [250/625]    eta: 0:00:23  time: 0.0609  data_time: 0.0083  memory: 506  \r\n",
      "05/10 22:34:32 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [300/625]    eta: 0:00:20  time: 0.0626  data_time: 0.0089  memory: 506  \r\n",
      "05/10 22:34:36 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [350/625]    eta: 0:00:17  time: 0.0627  data_time: 0.0086  memory: 506  \r\n",
      "05/10 22:34:39 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [400/625]    eta: 0:00:14  time: 0.0631  data_time: 0.0089  memory: 506  \r\n",
      "05/10 22:34:42 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [450/625]    eta: 0:00:10  time: 0.0616  data_time: 0.0088  memory: 506  \r\n",
      "05/10 22:34:45 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [500/625]    eta: 0:00:07  time: 0.0604  data_time: 0.0083  memory: 506  \r\n",
      "05/10 22:34:48 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [550/625]    eta: 0:00:04  time: 0.0606  data_time: 0.0083  memory: 506  \r\n",
      "05/10 22:34:51 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [600/625]    eta: 0:00:01  time: 0.0613  data_time: 0.0091  memory: 506  \r\n",
      "05/10 22:34:55 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Evaluating bbox...\r\n",
      "Loading and preparing results...\r\n",
      "DONE (t=0.43s)\r\n",
      "creating index...\r\n",
      "index created!\r\n",
      "Running per image evaluation...\r\n",
      "Evaluate annotation type *bbox*\r\n",
      "DONE (t=24.49s).\r\n",
      "Accumulating evaluation results...\r\n",
      "DONE (t=3.86s).\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.403\r\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.591\r\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.434\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.235\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.445\r\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.531\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.548\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.549\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.549\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.346\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.601\r\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.693\r\n",
      "05/10 22:35:25 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - bbox_mAP_copypaste: 0.403 0.591 0.434 0.235 0.445 0.531\r\n",
      "05/10 22:35:26 - mmengine - \u001B[4m\u001B[97mINFO\u001B[0m - Epoch(test) [625/625]    coco/bbox_mAP: 0.4030  coco/bbox_mAP_50: 0.5910  coco/bbox_mAP_75: 0.4340  coco/bbox_mAP_s: 0.2350  coco/bbox_mAP_m: 0.4450  coco/bbox_mAP_l: 0.5310  data_time: 0.0089  time: 0.0622\r\n"
     ]
    }
   ],
   "execution_count": 2,
   "source": "!python tools/test.py configs/yolox/yolox_x_8xb8-300e_coco.py checkpoints/yolox_x.pth --show",
   "id": "8365f20ab882ff93"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
